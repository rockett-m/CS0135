{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## HW03 Notebook\n",
    "\n",
    "Complete the following notebook, as described in the PDF for Homework 03 (included in the download with the starter code). Submit the following:\n",
    "1. This notebook file and `hw3.py`, along with your COLLABORATORS.txt file, to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "__NOTE__: The purpose of this notebook is to demonstrate the functionality implemented in `hw3.py`. As part of this demo, all analysis (i.e., questions that prompt for a short answer) are to be added to the notebook. Keep the order of the problems as listed in the assignment description. Furthermore, cells are provided as placeholders for each response; however, cells can be added as needed.\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/class/lcwv1h9p2a11ai).\n",
    "\n",
    "### Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "from hw3 import calc_confusion_matrix_for_threshold\n",
    "from hw3 import calc_percent_cancer\n",
    "from hw3 import calc_binary_metrics\n",
    "from hw3 import predict_0_always_classifier\n",
    "from hw3 import calc_accuracy\n",
    "from hw3 import print_perf_metrics_for_threshold\n",
    "from hw3 import calc_perf_metrics_for_threshold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1) Function to calculate TP, TN, FP, and FN.\n",
    "The following four calls to the function `calc_binary_metrics` to test it. This way, the function can be tested for several edge cases. ***Don't modify this.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all0 = np.zeros(10)\n",
    "all1 = np.ones(10)\n",
    "TP, TN, FP, FN = calc_binary_metrics(all0, all1)\n",
    "print(f\"0 vs 1\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all1, all0)\n",
    "print(f\"1 vs 0\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all1, all1)\n",
    "print(f\"1 vs 1\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all0, all0)\n",
    "print(f\"0 vs 0\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the dataset.\n",
    "\n",
    "The following should ***not*** be modified.\n",
    "\n",
    "After it runs, the various arrays it creates will contain the 2- or 3-feature input datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the x-data and y-class arrays\n",
    "x_train = np.loadtxt('./data/x_train.csv', delimiter=',', skiprows=1)\n",
    "x_test = np.loadtxt('./data/x_test.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "y_train = np.loadtxt('./data/y_train.csv', delimiter=',', skiprows=1)\n",
    "y_test = np.loadtxt('./data/y_test.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Inspect Data. The following should ***not*** be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_names = np.loadtxt(f'data/x_train.csv', delimiter=',', dtype=str, max_rows=1)\n",
    "print(f\"features: {feat_names}\\n\")\n",
    "target_name = np.loadtxt(f'data/x_test.csv', delimiter=',', dtype=str, max_rows=1)\n",
    "df_sampled_data = pd.DataFrame(x_test, columns=feat_names)\n",
    "df_sampled_data[str(target_name)] = y_test\n",
    "df_sampled_data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2) Compute the fraction of patients with cancer.\n",
    "\n",
    "Complete the following code.  Your solution needs to ***compute*** these values from the training and testing sets (i.e., don't simply hand-count and print the values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: modify these prints\n",
    "tr_percent = calc_percent_cancer(y_train)\n",
    "te_percent = calc_percent_cancer(y_test)\n",
    "\n",
    "print(\"Percent of data that has_cancer on TRAIN: %.3f\" % tr_percent)\n",
    "print(\"Percent of data that has_cancer on TEST : %.3f\" % te_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3) The predict-0-always baseline\n",
    "\n",
    "#### (i) Compute the accuracy of the always-0 classifier.\n",
    "\n",
    "Complete the functions to compute and calculate the accuracy of the always-0 classifier on validation and test outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: implement predict_0_always_classifer()\n",
    "y_train_pred = predict_0_always_classifier(x_train)\n",
    "y_test_pred = predict_0_always_classifier(x_test)\n",
    "\n",
    "acc_train = calc_accuracy(*calc_binary_metrics(y_train, y_train_pred))\n",
    "acc_test = calc_accuracy(*calc_binary_metrics(y_test, y_test_pred))\n",
    "print(\"acc on TRAIN: %.3f\" % acc_train) #TODO: modify these values\n",
    "print(\"acc on TEST : %.3f\" % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Print a confusion matrix for the always-0 classifier.\n",
    "\n",
    "Add code below to generate a confusion matrix for the always-0 classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: call print(calc_confusion_matrix_for_threshold(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Reflect on the accuracy of the always-0 classifier.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Analyze the various costs of using the always-0 classifier.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4: Basic Perceptron Models\n",
    "\n",
    "#### (i) Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Create a basic `Perceptron` classifier\n",
    "\n",
    "Fit a perceptron to the training data.  Print out accuracy on this data, as well as on testing data.  Print out a confusion matrix on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: train a basic perceptron model using default parameter values, and modify these accuracies below\n",
    "\n",
    "print(\"acc on TRAIN: %.3f\" % 0)\n",
    "print(\"acc on TEST : %.3f\" % 0)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix for TEST:\")\n",
    "# TODO: call print(calc_confusion_matrix_for_threshold(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Compare the `Perceptron` to the always-0 classifier.\n",
    "\n",
    "**Answer**:  TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Generate a series of regularized perceptron models\n",
    "Each model will use a different `alpha` value, multiplying that by the L2 penalty.  You will record and plot the accuracy of each model on both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_accuracy_list = list()\n",
    "test_accuracy_list = list()\n",
    "\n",
    "# TODO: create, fit models here and record accuracy of each (Implement functions needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Plot accuracy on train/test data across the different alpha values plotted on a logarithmic scale. Make sure to show title, legends, and axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO make plot\n",
    "plt.xlabel('log_10(alpha)');\n",
    "plt.ylabel('Accuracy');\n",
    "\n",
    "# TODO add legend, titles, etc. set x-scale appropriately\n",
    "# plt.legend(...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Discuss what the plot is showing you.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5: Decision functions and probabilistic predictions\n",
    "\n",
    "#### (a) Create two new sets of predictions\n",
    "\n",
    "Fit `Perceptron` and `CalibratedClassifierCV` models to the data.  Use their predictions to generate ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: fit a Perceptron and generate its decision_function() over the test data.\n",
    "\n",
    "# TODO: Build a CalibratedClassifierCV, using a Perceptron as its base_estimator,\n",
    "#       and generate its probabilistic predictions over the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO something like: fpr, tpr, thr = sklearn.metrics.roc_curve(...)\n",
    "\n",
    "plt.ylim([0, 1]);\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"False Postive rate (FPR)\");\n",
    "plt.ylabel(\"True Postive rate (TPR)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"AUC on TEST for Perceptron: %.3f\" % 0) #TODO: modify these values\n",
    "print(\"AUC on TEST for probabilistic model: %.3f\" % 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (b) Discuss the results above\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (c) Compute model metrics for different probabilistic thresholds\n",
    "\n",
    "Complete `calc_perf_metrics_for_threshold` that takes in a set of correct outputs, a matching set of probabilities generated by a classifier, and a threshold at which to set the positive decision probability, and returns a set of metrics if we use that threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (d) Compare the probabilistic classifier across multiple decision thresholds\n",
    "\n",
    "Try a range of thresholds for classifying data into the positive class (1).  For each threshold, compute the true positive rate (TPR) and positive predictive value (PPV).  Record the best value of each metric, along with the threshold that achieves it, and the *other* metric at that threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: test different thresholds to compute these values\n",
    "best_TPR = 0\n",
    "best_PPV_for_best_TPR = 0\n",
    "best_TPR_threshold = 0\n",
    "\n",
    "best_PPV = 0\n",
    "best_TPR_for_best_PPV = 0\n",
    "best_PPV_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best TPR threshold: %.4f => TPR: %.4f; PPV: %.4f\" % (best_TPR_threshold, best_TPR, best_PPV_for_best_TPR))\n",
    "print(\"Best PPV threshold: %.4f => PPV: %.4f; TPR: %.4f\" % (best_PPV_threshold, best_PPV, best_TPR_for_best_PPV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (e) Exploring different thresholds\n",
    "\n",
    "#### (i) Using default 0.5 threshold.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = 0.5\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Using threshold with highest TPR.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold that maximizes TPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = best_TPR_threshold\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Using threshold with highest PPV.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold that maximizes PPV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = best_PPV_threshold\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Compare the confusion matrices from (a)â€“(c) to analyze the different thresholds.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
