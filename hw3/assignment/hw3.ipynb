{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## HW03 Notebook\n",
    "\n",
    "Complete the following notebook, as described in the PDF for Homework 03 (included in the download with the starter code). Submit the following:\n",
    "1. This notebook file and `hw3.py`, along with your COLLABORATORS.txt file, to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "__NOTE__: The purpose of this notebook is to demonstrate the functionality implemented in `hw3.py`. As part of this demo, all analysis (i.e., questions that prompt for a short answer) are to be added to the notebook. Keep the order of the problems as listed in the assignment description. Furthermore, cells are provided as placeholders for each response; however, cells can be added as needed.\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/class/lcwv1h9p2a11ai).\n",
    "\n",
    "### Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "from hw3 import calc_confusion_matrix_for_threshold\n",
    "from hw3 import calc_percent_cancer\n",
    "from hw3 import calc_binary_metrics\n",
    "from hw3 import predict_0_always_classifier\n",
    "from hw3 import calc_accuracy\n",
    "from hw3 import print_perf_metrics_for_threshold\n",
    "from hw3 import calc_perf_metrics_for_threshold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1) Function to calculate TP, TN, FP, and FN.\n",
    "The following four calls to the function `calc_binary_metrics` to test it. This way, the function can be tested for several edge cases. ***Don't modify this.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vs 1\n",
      "========\n",
      "TP: 0.0\n",
      "TN: 0.0\n",
      "FP: 10.0\n",
      "FN: 0.0\n"
     ]
    }
   ],
   "source": [
    "all0 = np.zeros(10)\n",
    "all1 = np.ones(10)\n",
    "TP, TN, FP, FN = calc_binary_metrics(all0, all1)\n",
    "print(f\"0 vs 1\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 vs 0\n",
      "========\n",
      "TP: 0.0\n",
      "TN: 0.0\n",
      "FP: 0.0\n",
      "FN: 10.0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all1, all0)\n",
    "print(f\"1 vs 0\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 vs 1\n",
      "========\n",
      "TP: 10.0\n",
      "TN: 0.0\n",
      "FP: 0.0\n",
      "FN: 0.0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all1, all1)\n",
    "print(f\"1 vs 1\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vs 0\n",
      "========\n",
      "TP: 0.0\n",
      "TN: 10.0\n",
      "FP: 0.0\n",
      "FN: 0.0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all0, all0)\n",
    "print(f\"0 vs 0\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the dataset.\n",
    "\n",
    "The following should ***not*** be modified.\n",
    "\n",
    "After it runs, the various arrays it creates will contain the 2- or 3-feature input datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the x-data and y-class arrays\n",
    "x_train = np.loadtxt('./data/x_train.csv', delimiter=',', skiprows=1)\n",
    "x_test = np.loadtxt('./data/x_test.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "y_train = np.loadtxt('./data/y_train.csv', delimiter=',', skiprows=1)\n",
    "y_test = np.loadtxt('./data/y_test.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Inspect Data. The following should ***not*** be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['age' 'famhistory' 'marker']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "          age  famhistory    marker  ['age' 'famhistory' 'marker']\n169  64.29861         0.0  2.843979                            0.0\n49   78.46741         0.0  0.267086                            0.0\n94   57.14237         1.0  1.384837                            0.0\n122  66.15447         0.0  0.987860                            0.0\n72   60.23331         0.0  0.720714                            0.0\n62   64.22443         0.0  2.231875                            0.0\n16   62.85834         1.0  1.623482                            0.0\n129  59.16642         1.0  0.166644                            0.0\n9    68.42139         0.0  0.959714                            0.0\n130  62.93052         0.0  0.077108                            0.0\n153  68.03571         1.0  0.675789                            0.0\n168  65.99346         1.0  0.107068                            0.0\n139  63.46844         0.0  2.975184                            0.0\n103  60.38602         0.0  0.039325                            0.0\n46   61.28223         0.0  2.764809                            1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>famhistory</th>\n      <th>marker</th>\n      <th>['age' 'famhistory' 'marker']</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>169</th>\n      <td>64.29861</td>\n      <td>0.0</td>\n      <td>2.843979</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>78.46741</td>\n      <td>0.0</td>\n      <td>0.267086</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>57.14237</td>\n      <td>1.0</td>\n      <td>1.384837</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>66.15447</td>\n      <td>0.0</td>\n      <td>0.987860</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>60.23331</td>\n      <td>0.0</td>\n      <td>0.720714</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>64.22443</td>\n      <td>0.0</td>\n      <td>2.231875</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>62.85834</td>\n      <td>1.0</td>\n      <td>1.623482</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>59.16642</td>\n      <td>1.0</td>\n      <td>0.166644</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>68.42139</td>\n      <td>0.0</td>\n      <td>0.959714</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>62.93052</td>\n      <td>0.0</td>\n      <td>0.077108</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>68.03571</td>\n      <td>1.0</td>\n      <td>0.675789</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>65.99346</td>\n      <td>1.0</td>\n      <td>0.107068</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>63.46844</td>\n      <td>0.0</td>\n      <td>2.975184</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>60.38602</td>\n      <td>0.0</td>\n      <td>0.039325</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>61.28223</td>\n      <td>0.0</td>\n      <td>2.764809</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = np.loadtxt(f'data/x_train.csv', delimiter=',', dtype=str, max_rows=1)\n",
    "print(f\"features: {feat_names}\\n\")\n",
    "target_name = np.loadtxt(f'data/x_test.csv', delimiter=',', dtype=str, max_rows=1)\n",
    "df_sampled_data = pd.DataFrame(x_test, columns=feat_names)\n",
    "df_sampled_data[str(target_name)] = y_test\n",
    "df_sampled_data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2) Compute the fraction of patients with cancer.\n",
    "\n",
    "Complete the following code.  Your solution needs to ***compute*** these values from the training and testing sets (i.e., don't simply hand-count and print the values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of data that has_cancer on TRAIN: 14.035\n",
      "Percent of data that has_cancer on TEST : 13.889\n"
     ]
    }
   ],
   "source": [
    "#TODO: modify these prints\n",
    "tr_percent = calc_percent_cancer(y_train)\n",
    "te_percent = calc_percent_cancer(y_test)\n",
    "\n",
    "print(\"Percent of data that has_cancer on TRAIN: %.3f\" % tr_percent)\n",
    "print(\"Percent of data that has_cancer on TEST : %.3f\" % te_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3) The predict-0-always baseline\n",
    "\n",
    "#### (i) Compute the accuracy of the always-0 classifier.\n",
    "\n",
    "Complete the functions to compute and calculate the accuracy of the always-0 classifier on validation and test outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc on TRAIN: 0.860\n",
      "acc on TEST : 0.861\n"
     ]
    }
   ],
   "source": [
    "#TODO: implement predict_0_always_classifer()\n",
    "y_train_pred = predict_0_always_classifier(x_train)\n",
    "y_test_pred = predict_0_always_classifier(x_test)\n",
    "\n",
    "acc_train = calc_accuracy(*calc_binary_metrics(y_train, y_train_pred))\n",
    "acc_test = calc_accuracy(*calc_binary_metrics(y_test, y_test_pred))\n",
    "print(\"acc on TRAIN: %.3f\" % acc_train) #TODO: modify these values\n",
    "print(\"acc on TEST : %.3f\" % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Print a confusion matrix for the always-0 classifier.\n",
    "\n",
    "Add code below to generate a confusion matrix for the always-0 classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0  1\n",
      "True             \n",
      "0          155  0\n",
      "1           25  0\n"
     ]
    }
   ],
   "source": [
    "# TODO: call print(calc_confusion_matrix_for_threshold(...))\n",
    "print(calc_confusion_matrix_for_threshold(y_true_N=y_test, y_proba1_N=y_test_pred)) # args : y_true_N, y_proba1_N, thresh=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Reflect on the accuracy of the always-0 classifier.\n",
    "\n",
    "**Answer**: TODO\n",
    "(2) You will see reasonable accuracy for the simple baseline classifier. Why not just use it for this task? Your answer, written into the notebook as\n",
    "text, should detail the pluses and minuses of using this simple classifier\n",
    "\n",
    "This is pretty good accuracy at roughly 86%. Since we are always assuming there is no cancer; however, that is very dangerous if 14% of people have cancer and we choose not to biopsy them. That is unacceptable. If this was a social media algorithm like a recommender, 86% is plenty good, but life and death needs far better accuracy. It is safer to biopsy all patients to catch the 14% but you don't want to biopsy an unnecessary 86% on the other hand. That is why we can't use only a always-0 or always-1 predictor since surgery and people's lives are the consequences.\n",
    "\n",
    "DO THISSSSSSSSSSSSSSSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Analyze the various costs of using the always-0 classifier.\n",
    "\n",
    "**Answer**: TODO\n",
    "\n",
    "Additional costs of not taking biopsies of 14% of patients that have cancer beyond death is the doctors and/or hospital can be sued for negligence or medical malpractice.\n",
    "\n",
    "DO THISSSSSSSSSSSSSSSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4: Basic Perceptron Models\n",
    "\n",
    "#### (i) Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[63.78864 60.21136 70.18679 64.85663 68.6578  71.34671 74.77879 60.76143\n 62.87925 69.83581 58.65945 65.73421 72.44105 62.32544 64.59198 58.01468\n 61.01774 62.45436 65.7565  65.81664 63.54927 67.13424 63.36813 67.97187\n 67.18363 64.24229 63.94371 69.81638 65.50663 62.34288 64.58864 54.34343\n 76.31532 70.89838 66.54893 67.78315 76.53217 59.40677 74.09642 58.00622\n 65.99633 68.49203 59.8314  67.96156 70.39814 67.99323 66.97784 65.22306\n 64.05421 75.53773 58.62805 68.316   70.09425 61.86872 63.57636 57.40099\n 69.75618 66.46    63.07719 61.36214 54.02065 71.36636 67.21446 59.90642\n 72.66306 66.35931 67.05412 61.98321 62.9514  64.32439 61.20963 70.28268\n 63.09303 66.16218 54.60774 65.87422 59.57447 65.18739 70.12766 63.00902\n 63.69997 68.29043 60.44851 63.37096 68.61874 63.60289 62.10342 68.16631\n 63.92532 67.7188  66.06847 61.40981 61.69149 64.83163 60.76701 69.73871\n 65.49047 64.94543 64.36356 59.46868 54.69748 66.83841 68.26522 71.69258\n 57.65518 56.9712  65.61407 62.48288 64.82024 66.96828 61.54588 65.12152\n 68.84058 68.45389 62.79475 63.79015 60.45181 67.07994 57.15098 65.18436\n 66.24428 69.25652 45.30359 63.19863 69.79289 71.92839 61.03221 73.00558\n 60.60762 64.17079 63.67994 58.30753 56.81948 51.5556  65.3263  62.71746\n 71.32385 73.46328 67.67131 64.42557 58.61325 70.23822 65.02428 68.28202\n 66.37389 66.44272 65.24432 63.2154  67.17767 68.39446 60.47071 70.26044\n 58.27445 61.16592 60.98792 67.07034 70.55273 66.79304 65.02237 73.49937\n 59.62656 64.11355 69.96291 69.38736 68.6612  53.73625 60.12118 62.5235\n 63.71798 60.2058  71.43584 61.96416 70.28848 69.6695  62.82744 68.368\n 64.71027 67.03373 63.96486 61.43227 69.51936 65.49502 74.57713 67.63158\n 62.2402  62.99156 68.20441 64.11584 72.44943 64.03445 63.89442 62.93747\n 65.15671 66.55087 64.25269 68.69183 59.85032 59.29411 63.19449 65.73213\n 67.59895 64.22717 64.08953 71.25349 67.57849 63.60241 69.68842 61.47312\n 66.57789 63.43912 69.72916 60.05052 65.7537  66.31138 59.39383 71.01147\n 64.57951 55.01429 70.61745 62.93702 69.01857 64.25861 76.00014 67.78082\n 61.29579 65.08706 66.10999 50.48239 63.49087 61.86514 65.47884 57.17504\n 66.65852 59.92947 72.27111 67.03914 68.83257 70.29654 59.73852 67.01884\n 60.00595 64.27274 67.3124  54.45557 63.62803 66.09628 65.32578 68.53159\n 52.96059 65.08852 60.61732 62.15931 72.4721  73.10541 69.5911  73.90347\n 60.11263 62.93098 59.18258 61.79989 60.70201 65.76543 64.66387 65.03281\n 67.39896 65.34932 55.69534 59.11484 75.31924 69.24045 61.82353 63.35165\n 67.02776 60.58875 61.75168 65.15668 66.30898 66.34698 69.89828 63.03135\n 65.24892 68.40578 67.85812 61.17285 74.07236 65.99361 65.79408 64.3119\n 65.44019 64.94736 56.75846 60.70569 66.60336 56.11819 69.35155 64.75623\n 65.23592 55.94527 63.60876 67.39    56.38057 67.70454 70.11369 70.26424\n 68.14637 62.92625 64.73486 58.09938 68.8804  64.05187 65.54733 79.76653\n 65.7288  61.60319 66.41716 70.01092 65.45943 68.62294 66.46255 68.42844\n 56.44126 61.01159 64.6208  61.81751 66.66376 61.65575 70.90057 66.29403\n 63.31944 58.38802 62.60334 57.95905 64.01502 68.7723  65.56735 72.00404\n 70.71751 68.75684 65.91357 57.83153 69.32669 65.91871 68.7872  63.24149\n 68.75526 63.3393  75.56043 61.56926 58.02626 60.44228 62.67277 58.19759\n 74.29142 58.73467 66.78515 75.38474 61.66132 71.03853 62.22564 60.88992\n 72.578   57.00854 58.98153 66.55123 62.23393 65.36638 65.77481 69.83913\n 70.89852 60.76242 63.76203 68.88636 65.73548 58.43612 67.50124 74.08248\n 61.73415 60.30972 61.32673 61.09392 58.0386  62.70977 67.02632 69.00488\n 62.49572 72.49593 58.66271 62.63218 69.77619 60.47538 68.25851 64.2628\n 66.66345 64.84    70.61486 62.62358 55.90627 63.80734 60.95815 61.82711\n 60.17276 74.32897 55.60033 69.9508  64.25385 70.6036  68.03888 64.72021\n 72.4613  65.02283 69.51903 63.14412 65.79142 68.28604 68.31233 75.12341\n 58.53482 67.38682 55.29354 66.06262 65.11663 71.21556 65.0612  69.58582\n 75.32822 79.04468 66.01958 61.50447 72.74631 67.93705 60.15109 70.78928\n 77.40621 64.92082 72.20895 66.80156 64.14617 73.03004 62.31853 66.94241\n 53.83488 61.1411  65.61685 68.07181 66.59802 71.74419 68.28448 60.62355\n 65.71225 71.37019 71.67717 57.4673  57.8602  70.53944 78.56901 60.50634\n 65.99091 65.74824 60.49458 66.01667 56.04074 70.99741 66.97537 60.29137\n 62.54554 59.3563  67.80624 70.3428  57.58475 61.66628 66.67097 67.23944\n 66.54843 60.57935 69.09983 71.22737 62.58792 60.45244 64.74159 60.61064\n 67.59258 66.941   68.21297 65.07773 73.28582 62.21901 67.54557 66.88622\n 60.90358 57.11904 68.38504 54.53442 66.19933 65.29849 60.05769 64.7915\n 62.68991 60.25611 66.41076 71.79935 62.7063  69.05017 65.25371 68.56496\n 67.21479 69.2804  67.57489 64.48709 58.61883 68.96118 60.22693 63.27031\n 65.80829 62.99549 65.48821 61.96559 64.38535 73.63928 74.72022 68.37849\n 58.3893  61.75411 62.01424 68.83849 61.62151 62.36021 69.72533 74.95695\n 65.05784 69.95479 58.10442 68.07715 74.6252  64.73679 65.12194 58.01107\n 60.88333 57.72224 67.96124 61.09707 55.26783 67.33332 55.04963 60.02258\n 65.14695 71.63702 61.68419 64.61358 67.4205  60.65023 63.3249  65.417\n 66.19345 60.64941 66.85851 71.2843  70.80365 65.86873 69.01793 70.20066\n 61.91515 68.65911 64.5041  62.07671 58.68771 62.76329 65.357   60.94031\n 56.76624 66.97219].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhw3\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m standardize_data\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#TODO\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m X_train, X_test \u001B[38;5;241m=\u001B[39m \u001B[43mstandardize_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/CodeProjects/Tufts/CS0135/hw3/assignment/hw3.py:193\u001B[0m, in \u001B[0;36mstandardize_data\u001B[0;34m(X_train, X_test)\u001B[0m\n\u001B[1;32m    190\u001B[0m scaler \u001B[38;5;241m=\u001B[39m MinMaxScaler(feature_range\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    192\u001B[0m \u001B[38;5;66;03m# print(X_train[:,1])\u001B[39;00m\n\u001B[0;32m--> 193\u001B[0m age_scaled \u001B[38;5;241m=\u001B[39m \u001B[43mMinMaxScaler\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# age_scaled = scaler.fit_transform(X_train[:,0])\u001B[39;00m\n\u001B[1;32m    195\u001B[0m marker_scaled \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mfit_transform(X_train[:,\u001B[38;5;241m2\u001B[39m])\u001B[38;5;241m.\u001B[39mreshape()\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/ml_0135/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 142\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    144\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    145\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    146\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    147\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    148\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/ml_0135/lib/python3.10/site-packages/sklearn/base.py:859\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[1;32m    856\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    858\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[0;32m--> 859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[1;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[0;32m~/miniconda3/envs/ml_0135/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:427\u001B[0m, in \u001B[0;36mMinMaxScaler.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;66;03m# Reset internal state before fitting\u001B[39;00m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[0;32m--> 427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpartial_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/ml_0135/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:466\u001B[0m, in \u001B[0;36mMinMaxScaler.partial_fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    461\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMinMaxScaler does not support sparse input. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    462\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConsider using MaxAbsScaler instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    463\u001B[0m     )\n\u001B[1;32m    465\u001B[0m first_pass \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_samples_seen_\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 466\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfirst_pass\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFLOAT_DTYPES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    471\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    473\u001B[0m data_min \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnanmin(X, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    474\u001B[0m data_max \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnanmax(X, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/ml_0135/lib/python3.10/site-packages/sklearn/base.py:546\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    545\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 546\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    547\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    548\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[0;32m~/miniconda3/envs/ml_0135/lib/python3.10/site-packages/sklearn/utils/validation.py:902\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    900\u001B[0m     \u001B[38;5;66;03m# If input is 1D raise error\u001B[39;00m\n\u001B[1;32m    901\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 902\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    903\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124marray=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    904\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    905\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    906\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif it contains a single sample.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m    907\u001B[0m         )\n\u001B[1;32m    909\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    910\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    912\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    913\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[63.78864 60.21136 70.18679 64.85663 68.6578  71.34671 74.77879 60.76143\n 62.87925 69.83581 58.65945 65.73421 72.44105 62.32544 64.59198 58.01468\n 61.01774 62.45436 65.7565  65.81664 63.54927 67.13424 63.36813 67.97187\n 67.18363 64.24229 63.94371 69.81638 65.50663 62.34288 64.58864 54.34343\n 76.31532 70.89838 66.54893 67.78315 76.53217 59.40677 74.09642 58.00622\n 65.99633 68.49203 59.8314  67.96156 70.39814 67.99323 66.97784 65.22306\n 64.05421 75.53773 58.62805 68.316   70.09425 61.86872 63.57636 57.40099\n 69.75618 66.46    63.07719 61.36214 54.02065 71.36636 67.21446 59.90642\n 72.66306 66.35931 67.05412 61.98321 62.9514  64.32439 61.20963 70.28268\n 63.09303 66.16218 54.60774 65.87422 59.57447 65.18739 70.12766 63.00902\n 63.69997 68.29043 60.44851 63.37096 68.61874 63.60289 62.10342 68.16631\n 63.92532 67.7188  66.06847 61.40981 61.69149 64.83163 60.76701 69.73871\n 65.49047 64.94543 64.36356 59.46868 54.69748 66.83841 68.26522 71.69258\n 57.65518 56.9712  65.61407 62.48288 64.82024 66.96828 61.54588 65.12152\n 68.84058 68.45389 62.79475 63.79015 60.45181 67.07994 57.15098 65.18436\n 66.24428 69.25652 45.30359 63.19863 69.79289 71.92839 61.03221 73.00558\n 60.60762 64.17079 63.67994 58.30753 56.81948 51.5556  65.3263  62.71746\n 71.32385 73.46328 67.67131 64.42557 58.61325 70.23822 65.02428 68.28202\n 66.37389 66.44272 65.24432 63.2154  67.17767 68.39446 60.47071 70.26044\n 58.27445 61.16592 60.98792 67.07034 70.55273 66.79304 65.02237 73.49937\n 59.62656 64.11355 69.96291 69.38736 68.6612  53.73625 60.12118 62.5235\n 63.71798 60.2058  71.43584 61.96416 70.28848 69.6695  62.82744 68.368\n 64.71027 67.03373 63.96486 61.43227 69.51936 65.49502 74.57713 67.63158\n 62.2402  62.99156 68.20441 64.11584 72.44943 64.03445 63.89442 62.93747\n 65.15671 66.55087 64.25269 68.69183 59.85032 59.29411 63.19449 65.73213\n 67.59895 64.22717 64.08953 71.25349 67.57849 63.60241 69.68842 61.47312\n 66.57789 63.43912 69.72916 60.05052 65.7537  66.31138 59.39383 71.01147\n 64.57951 55.01429 70.61745 62.93702 69.01857 64.25861 76.00014 67.78082\n 61.29579 65.08706 66.10999 50.48239 63.49087 61.86514 65.47884 57.17504\n 66.65852 59.92947 72.27111 67.03914 68.83257 70.29654 59.73852 67.01884\n 60.00595 64.27274 67.3124  54.45557 63.62803 66.09628 65.32578 68.53159\n 52.96059 65.08852 60.61732 62.15931 72.4721  73.10541 69.5911  73.90347\n 60.11263 62.93098 59.18258 61.79989 60.70201 65.76543 64.66387 65.03281\n 67.39896 65.34932 55.69534 59.11484 75.31924 69.24045 61.82353 63.35165\n 67.02776 60.58875 61.75168 65.15668 66.30898 66.34698 69.89828 63.03135\n 65.24892 68.40578 67.85812 61.17285 74.07236 65.99361 65.79408 64.3119\n 65.44019 64.94736 56.75846 60.70569 66.60336 56.11819 69.35155 64.75623\n 65.23592 55.94527 63.60876 67.39    56.38057 67.70454 70.11369 70.26424\n 68.14637 62.92625 64.73486 58.09938 68.8804  64.05187 65.54733 79.76653\n 65.7288  61.60319 66.41716 70.01092 65.45943 68.62294 66.46255 68.42844\n 56.44126 61.01159 64.6208  61.81751 66.66376 61.65575 70.90057 66.29403\n 63.31944 58.38802 62.60334 57.95905 64.01502 68.7723  65.56735 72.00404\n 70.71751 68.75684 65.91357 57.83153 69.32669 65.91871 68.7872  63.24149\n 68.75526 63.3393  75.56043 61.56926 58.02626 60.44228 62.67277 58.19759\n 74.29142 58.73467 66.78515 75.38474 61.66132 71.03853 62.22564 60.88992\n 72.578   57.00854 58.98153 66.55123 62.23393 65.36638 65.77481 69.83913\n 70.89852 60.76242 63.76203 68.88636 65.73548 58.43612 67.50124 74.08248\n 61.73415 60.30972 61.32673 61.09392 58.0386  62.70977 67.02632 69.00488\n 62.49572 72.49593 58.66271 62.63218 69.77619 60.47538 68.25851 64.2628\n 66.66345 64.84    70.61486 62.62358 55.90627 63.80734 60.95815 61.82711\n 60.17276 74.32897 55.60033 69.9508  64.25385 70.6036  68.03888 64.72021\n 72.4613  65.02283 69.51903 63.14412 65.79142 68.28604 68.31233 75.12341\n 58.53482 67.38682 55.29354 66.06262 65.11663 71.21556 65.0612  69.58582\n 75.32822 79.04468 66.01958 61.50447 72.74631 67.93705 60.15109 70.78928\n 77.40621 64.92082 72.20895 66.80156 64.14617 73.03004 62.31853 66.94241\n 53.83488 61.1411  65.61685 68.07181 66.59802 71.74419 68.28448 60.62355\n 65.71225 71.37019 71.67717 57.4673  57.8602  70.53944 78.56901 60.50634\n 65.99091 65.74824 60.49458 66.01667 56.04074 70.99741 66.97537 60.29137\n 62.54554 59.3563  67.80624 70.3428  57.58475 61.66628 66.67097 67.23944\n 66.54843 60.57935 69.09983 71.22737 62.58792 60.45244 64.74159 60.61064\n 67.59258 66.941   68.21297 65.07773 73.28582 62.21901 67.54557 66.88622\n 60.90358 57.11904 68.38504 54.53442 66.19933 65.29849 60.05769 64.7915\n 62.68991 60.25611 66.41076 71.79935 62.7063  69.05017 65.25371 68.56496\n 67.21479 69.2804  67.57489 64.48709 58.61883 68.96118 60.22693 63.27031\n 65.80829 62.99549 65.48821 61.96559 64.38535 73.63928 74.72022 68.37849\n 58.3893  61.75411 62.01424 68.83849 61.62151 62.36021 69.72533 74.95695\n 65.05784 69.95479 58.10442 68.07715 74.6252  64.73679 65.12194 58.01107\n 60.88333 57.72224 67.96124 61.09707 55.26783 67.33332 55.04963 60.02258\n 65.14695 71.63702 61.68419 64.61358 67.4205  60.65023 63.3249  65.417\n 66.19345 60.64941 66.85851 71.2843  70.80365 65.86873 69.01793 70.20066\n 61.91515 68.65911 64.5041  62.07671 58.68771 62.76329 65.357   60.94031\n 56.76624 66.97219].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from hw3 import standardize_data\n",
    "\n",
    "#TODO\n",
    "X_train, X_test = standardize_data(X_train=x_train, X_test=x_test)\n",
    "\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Create a basic `Perceptron` classifier\n",
    "\n",
    "Fit a perceptron to the training data.  Print out accuracy on this data, as well as on testing data.  Print out a confusion matrix on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: train a basic perceptron model using default parameter values, and modify these accuracies below\n",
    "\n",
    "print(\"acc on TRAIN: %.3f\" % 0)\n",
    "print(\"acc on TEST : %.3f\" % 0)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix for TEST:\")\n",
    "# TODO: call print(calc_confusion_matrix_for_threshold(...))\n",
    "\n",
    "# print(calc_confusion_matrix_for_threshold(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Compare the `Perceptron` to the always-0 classifier.\n",
    "\n",
    "**Answer**:  TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Generate a series of regularized perceptron models\n",
    "Each model will use a different `alpha` value, multiplying that by the L2 penalty.  You will record and plot the accuracy of each model on both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_accuracy_list = list()\n",
    "test_accuracy_list = list()\n",
    "\n",
    "# TODO: create, fit models here and record accuracy of each (Implement functions needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Plot accuracy on train/test data across the different alpha values plotted on a logarithmic scale. Make sure to show title, legends, and axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO make plot\n",
    "plt.xlabel('log_10(alpha)');\n",
    "plt.ylabel('Accuracy');\n",
    "\n",
    "# TODO add legend, titles, etc. set x-scale appropriately\n",
    "# plt.legend(...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Discuss what the plot is showing you.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5: Decision functions and probabilistic predictions\n",
    "\n",
    "#### (a) Create two new sets of predictions\n",
    "\n",
    "Fit `Perceptron` and `CalibratedClassifierCV` models to the data.  Use their predictions to generate ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: fit a Perceptron and generate its decision_function() over the test data.\n",
    "\n",
    "# TODO: Build a CalibratedClassifierCV, using a Perceptron as its base_estimator,\n",
    "#       and generate its probabilistic predictions over the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO something like: fpr, tpr, thr = sklearn.metrics.roc_curve(...)\n",
    "\n",
    "plt.ylim([0, 1]);\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"False Postive rate (FPR)\");\n",
    "plt.ylabel(\"True Postive rate (TPR)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"AUC on TEST for Perceptron: %.3f\" % 0) #TODO: modify these values\n",
    "print(\"AUC on TEST for probabilistic model: %.3f\" % 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (b) Discuss the results above\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (c) Compute model metrics for different probabilistic thresholds\n",
    "\n",
    "Complete `calc_perf_metrics_for_threshold` that takes in a set of correct outputs, a matching set of probabilities generated by a classifier, and a threshold at which to set the positive decision probability, and returns a set of metrics if we use that threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (d) Compare the probabilistic classifier across multiple decision thresholds\n",
    "\n",
    "Try a range of thresholds for classifying data into the positive class (1).  For each threshold, compute the true positive rate (TPR) and positive predictive value (PPV).  Record the best value of each metric, along with the threshold that achieves it, and the *other* metric at that threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: test different thresholds to compute these values\n",
    "best_TPR = 0\n",
    "best_PPV_for_best_TPR = 0\n",
    "best_TPR_threshold = 0\n",
    "\n",
    "best_PPV = 0\n",
    "best_TPR_for_best_PPV = 0\n",
    "best_PPV_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best TPR threshold: %.4f => TPR: %.4f; PPV: %.4f\" % (best_TPR_threshold, best_TPR, best_PPV_for_best_TPR))\n",
    "print(\"Best PPV threshold: %.4f => PPV: %.4f; TPR: %.4f\" % (best_PPV_threshold, best_PPV, best_TPR_for_best_PPV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (e) Exploring different thresholds\n",
    "\n",
    "#### (i) Using default 0.5 threshold.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = 0.5\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Using threshold with highest TPR.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold that maximizes TPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = best_TPR_threshold\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Using threshold with highest PPV.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold that maximizes PPV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = best_PPV_threshold\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Compare the confusion matrices from (a)â€“(c) to analyze the different thresholds.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
