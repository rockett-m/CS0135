{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## HW03 Notebook\n",
    "\n",
    "Complete the following notebook, as described in the PDF for Homework 03 (included in the download with the starter code). Submit the following:\n",
    "1. This notebook file and `hw3.py`, along with your COLLABORATORS.txt file, to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "__NOTE__: The purpose of this notebook is to demonstrate the functionality implemented in `hw3.py`. As part of this demo, all analysis (i.e., questions that prompt for a short answer) are to be added to the notebook. Keep the order of the problems as listed in the assignment description. Furthermore, cells are provided as placeholders for each response; however, cells can be added as needed.\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/class/lcwv1h9p2a11ai).\n",
    "\n",
    "### Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "from hw3 import calc_confusion_matrix_for_threshold\n",
    "from hw3 import calc_percent_cancer\n",
    "from hw3 import calc_binary_metrics\n",
    "from hw3 import predict_0_always_classifier\n",
    "from hw3 import calc_accuracy\n",
    "from hw3 import print_perf_metrics_for_threshold\n",
    "from hw3 import calc_perf_metrics_for_threshold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1) Function to calculate TP, TN, FP, and FN.\n",
    "The following four calls to the function `calc_binary_metrics` to test it. This way, the function can be tested for several edge cases. ***Don't modify this.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vs 1\n",
      "========\n",
      "TP: 0.0\n",
      "TN: 0.0\n",
      "FP: 10.0\n",
      "FN: 0.0\n"
     ]
    }
   ],
   "source": [
    "all0 = np.zeros(10)\n",
    "all1 = np.ones(10)\n",
    "TP, TN, FP, FN = calc_binary_metrics(all0, all1)\n",
    "print(f\"0 vs 1\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 vs 0\n",
      "========\n",
      "TP: 0.0\n",
      "TN: 0.0\n",
      "FP: 0.0\n",
      "FN: 10.0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all1, all0)\n",
    "print(f\"1 vs 0\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 vs 1\n",
      "========\n",
      "TP: 10.0\n",
      "TN: 0.0\n",
      "FP: 0.0\n",
      "FN: 0.0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all1, all1)\n",
    "print(f\"1 vs 1\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vs 0\n",
      "========\n",
      "TP: 0.0\n",
      "TN: 10.0\n",
      "FP: 0.0\n",
      "FN: 0.0\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = calc_binary_metrics(all0, all0)\n",
    "print(f\"0 vs 0\\n========\\nTP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the dataset.\n",
    "\n",
    "The following should ***not*** be modified.\n",
    "\n",
    "After it runs, the various arrays it creates will contain the 2- or 3-feature input datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the x-data and y-class arrays\n",
    "x_train = np.loadtxt('./data/x_train.csv', delimiter=',', skiprows=1)\n",
    "x_test = np.loadtxt('./data/x_test.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "y_train = np.loadtxt('./data/y_train.csv', delimiter=',', skiprows=1)\n",
    "y_test = np.loadtxt('./data/y_test.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Inspect Data. The following should ***not*** be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['age' 'famhistory' 'marker']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "          age  famhistory    marker  ['age' 'famhistory' 'marker']\n17   59.58395         0.0  0.707959                            0.0\n160  61.38799         0.0  0.439202                            0.0\n145  70.56544         0.0  2.302760                            1.0\n33   62.17199         0.0  3.000216                            0.0\n57   75.35253         0.0  0.581305                            0.0\n76   63.12003         1.0  0.505131                            0.0\n100  71.86153         0.0  0.879809                            0.0\n68   68.01037         0.0  0.188447                            1.0\n143  61.56339         0.0  0.432614                            0.0\n61   59.86173         0.0  0.425001                            0.0\n58   64.48171         0.0  0.136261                            0.0\n159  64.84370         0.0  0.594441                            0.0\n29   65.20155         0.0  0.531104                            1.0\n165  65.83802         0.0  0.040094                            0.0\n155  61.31017         0.0  0.927381                            0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>famhistory</th>\n      <th>marker</th>\n      <th>['age' 'famhistory' 'marker']</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>59.58395</td>\n      <td>0.0</td>\n      <td>0.707959</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>61.38799</td>\n      <td>0.0</td>\n      <td>0.439202</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>70.56544</td>\n      <td>0.0</td>\n      <td>2.302760</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>62.17199</td>\n      <td>0.0</td>\n      <td>3.000216</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>75.35253</td>\n      <td>0.0</td>\n      <td>0.581305</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>63.12003</td>\n      <td>1.0</td>\n      <td>0.505131</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>71.86153</td>\n      <td>0.0</td>\n      <td>0.879809</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>68.01037</td>\n      <td>0.0</td>\n      <td>0.188447</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>61.56339</td>\n      <td>0.0</td>\n      <td>0.432614</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>59.86173</td>\n      <td>0.0</td>\n      <td>0.425001</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>64.48171</td>\n      <td>0.0</td>\n      <td>0.136261</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>64.84370</td>\n      <td>0.0</td>\n      <td>0.594441</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>65.20155</td>\n      <td>0.0</td>\n      <td>0.531104</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>65.83802</td>\n      <td>0.0</td>\n      <td>0.040094</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>61.31017</td>\n      <td>0.0</td>\n      <td>0.927381</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = np.loadtxt(f'data/x_train.csv', delimiter=',', dtype=str, max_rows=1)\n",
    "print(f\"features: {feat_names}\\n\")\n",
    "target_name = np.loadtxt(f'data/x_test.csv', delimiter=',', dtype=str, max_rows=1)\n",
    "df_sampled_data = pd.DataFrame(x_test, columns=feat_names)\n",
    "df_sampled_data[str(target_name)] = y_test\n",
    "df_sampled_data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2) Compute the fraction of patients with cancer.\n",
    "\n",
    "Complete the following code.  Your solution needs to ***compute*** these values from the training and testing sets (i.e., don't simply hand-count and print the values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of data that has_cancer on TRAIN: 14.035\n",
      "Percent of data that has_cancer on TEST : 13.889\n"
     ]
    }
   ],
   "source": [
    "#TODO: modify these prints\n",
    "tr_percent = calc_percent_cancer(y_train)\n",
    "te_percent = calc_percent_cancer(y_test)\n",
    "\n",
    "print(\"Percent of data that has_cancer on TRAIN: %.3f\" % tr_percent)\n",
    "print(\"Percent of data that has_cancer on TEST : %.3f\" % te_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3) The predict-0-always baseline\n",
    "\n",
    "#### (i) Compute the accuracy of the always-0 classifier.\n",
    "\n",
    "Complete the functions to compute and calculate the accuracy of the always-0 classifier on validation and test outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg accuracy on x_train: y_train_pred = 2.542105263157895\n",
      "neg accuracy on x_test: y_test_pred = 2.533333333333333\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 9\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mneg accuracy on x_train: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_train_pred \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mneg accuracy on x_test: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_test_pred \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m acc_train \u001B[38;5;241m=\u001B[39m calc_accuracy(\u001B[38;5;241m*\u001B[39m\u001B[43mcalc_binary_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_pred\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     10\u001B[0m acc_test \u001B[38;5;241m=\u001B[39m calc_accuracy(\u001B[38;5;241m*\u001B[39mcalc_binary_metrics(y_test, y_test_pred))\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124macc on TRAIN: \u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m acc_train) \u001B[38;5;66;03m#TODO: modify these values\u001B[39;00m\n",
      "File \u001B[0;32m~/CodeProjects/Tufts/CS0135/hw3/assignment/hw3.py:102\u001B[0m, in \u001B[0;36mcalc_binary_metrics\u001B[0;34m(y_true_N, y_hat_N)\u001B[0m\n\u001B[1;32m     99\u001B[0m FP \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m    100\u001B[0m FN \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ytrue, yhat \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43my_true_N\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_hat_N\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ytrue \u001B[38;5;241m==\u001B[39m yhat \u001B[38;5;129;01mand\u001B[39;00m ytrue \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m: \u001B[38;5;66;03m# no cancer and prediction correct\u001B[39;00m\n\u001B[1;32m    104\u001B[0m         TN \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "#TODO: implement predict_0_always_classifer()\n",
    "y_train_pred = predict_0_always_classifier(x_train)\n",
    "y_test_pred = predict_0_always_classifier(x_test)\n",
    "\n",
    "print(f'neg accuracy on x_train: {y_train_pred = }')\n",
    "print(f'neg accuracy on x_test: {y_test_pred = }')\n",
    "\n",
    "\n",
    "acc_train = calc_accuracy(*calc_binary_metrics(y_train, y_train_pred))\n",
    "acc_test = calc_accuracy(*calc_binary_metrics(y_test, y_test_pred))\n",
    "print(\"acc on TRAIN: %.3f\" % acc_train) #TODO: modify these values\n",
    "print(\"acc on TEST : %.3f\" % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Print a confusion matrix for the always-0 classifier.\n",
    "\n",
    "Add code below to generate a confusion matrix for the always-0 classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: call print(calc_confusion_matrix_for_threshold(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Reflect on the accuracy of the always-0 classifier.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Analyze the various costs of using the always-0 classifier.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4: Basic Perceptron Models\n",
    "\n",
    "#### (i) Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Create a basic `Perceptron` classifier\n",
    "\n",
    "Fit a perceptron to the training data.  Print out accuracy on this data, as well as on testing data.  Print out a confusion matrix on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: train a basic perceptron model using default parameter values, and modify these accuracies below\n",
    "\n",
    "print(\"acc on TRAIN: %.3f\" % 0)\n",
    "print(\"acc on TEST : %.3f\" % 0)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix for TEST:\")\n",
    "# TODO: call print(calc_confusion_matrix_for_threshold(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Compare the `Perceptron` to the always-0 classifier.\n",
    "\n",
    "**Answer**:  TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Generate a series of regularized perceptron models\n",
    "Each model will use a different `alpha` value, multiplying that by the L2 penalty.  You will record and plot the accuracy of each model on both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_accuracy_list = list()\n",
    "test_accuracy_list = list()\n",
    "\n",
    "# TODO: create, fit models here and record accuracy of each (Implement functions needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Plot accuracy on train/test data across the different alpha values plotted on a logarithmic scale. Make sure to show title, legends, and axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO make plot\n",
    "plt.xlabel('log_10(alpha)');\n",
    "plt.ylabel('Accuracy');\n",
    "\n",
    "# TODO add legend, titles, etc. set x-scale appropriately\n",
    "# plt.legend(...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Discuss what the plot is showing you.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5: Decision functions and probabilistic predictions\n",
    "\n",
    "#### (a) Create two new sets of predictions\n",
    "\n",
    "Fit `Perceptron` and `CalibratedClassifierCV` models to the data.  Use their predictions to generate ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: fit a Perceptron and generate its decision_function() over the test data.\n",
    "\n",
    "# TODO: Build a CalibratedClassifierCV, using a Perceptron as its base_estimator,\n",
    "#       and generate its probabilistic predictions over the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO something like: fpr, tpr, thr = sklearn.metrics.roc_curve(...)\n",
    "\n",
    "plt.ylim([0, 1]);\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"False Postive rate (FPR)\");\n",
    "plt.ylabel(\"True Postive rate (TPR)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"AUC on TEST for Perceptron: %.3f\" % 0) #TODO: modify these values\n",
    "print(\"AUC on TEST for probabilistic model: %.3f\" % 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (b) Discuss the results above\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (c) Compute model metrics for different probabilistic thresholds\n",
    "\n",
    "Complete `calc_perf_metrics_for_threshold` that takes in a set of correct outputs, a matching set of probabilities generated by a classifier, and a threshold at which to set the positive decision probability, and returns a set of metrics if we use that threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (d) Compare the probabilistic classifier across multiple decision thresholds\n",
    "\n",
    "Try a range of thresholds for classifying data into the positive class (1).  For each threshold, compute the true positive rate (TPR) and positive predictive value (PPV).  Record the best value of each metric, along with the threshold that achieves it, and the *other* metric at that threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: test different thresholds to compute these values\n",
    "best_TPR = 0\n",
    "best_PPV_for_best_TPR = 0\n",
    "best_TPR_threshold = 0\n",
    "\n",
    "best_PPV = 0\n",
    "best_TPR_for_best_PPV = 0\n",
    "best_PPV_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best TPR threshold: %.4f => TPR: %.4f; PPV: %.4f\" % (best_TPR_threshold, best_TPR, best_PPV_for_best_TPR))\n",
    "print(\"Best PPV threshold: %.4f => PPV: %.4f; TPR: %.4f\" % (best_PPV_threshold, best_PPV, best_TPR_for_best_PPV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (e) Exploring different thresholds\n",
    "\n",
    "#### (i) Using default 0.5 threshold.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = 0.5\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (ii) Using threshold with highest TPR.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold that maximizes TPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = best_TPR_threshold\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iii) Using threshold with highest PPV.\n",
    "\n",
    "Generate confusion matrix and metrics for probabilistic classifier, using threshold that maximizes PPV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_thr = best_PPV_threshold\n",
    "print(\"ON THE TEST SET:\")\n",
    "print(\"Chosen best threshold = %.4f\" % best_thr)\n",
    "print(\"\")\n",
    "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
    "print(\"\")\n",
    "# TODO: print_perf_metrics_for_threshold(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (iv) Compare the confusion matrices from (a)â€“(c) to analyze the different thresholds.\n",
    "\n",
    "**Answer**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
