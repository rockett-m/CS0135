{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name and ID\n",
    "\n",
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW04 Code\n",
    "\n",
    "You will complete the following notebook, as described in the PDF for Homework 04 (included in the download with the starter code).  You will submit:\n",
    "1. This notebook file (`hw04.ipynb`), `implementation.py`, and two files for both trees images, i.e., `full`, `full.pdf`, `simple`, and `simple.pdf` (PDFs and text files generated using `graphviz` within the code). HINT: `render()`, and it should be clear when to use it, i.e., #3). Compress all files mentioned and submit to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/class/lcwv1h9p2a11ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import required libraries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T00:21:23.019631Z",
     "end_time": "2023-04-16T00:21:23.064732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.tree\n",
    "import graphviz\n",
    "\n",
    "from implementation import information_remainder, counting_heuristic, set_entropy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "You should start by computing the two heuristic values for the toy data described in the assignment handout. You should then load the two versions of the abalone data, compute the two heuristic values on features (for the simplified data), and then build decision trees for each set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Compute both heuristics for toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "feature_names = np.array([\"A\", \"B\"])\n",
    "feature_len = 2\n",
    "classes = [0, 1]\n",
    "\n",
    "x_set = np.array([[1, 1], [1, 1], [0, 1], [0, 0], [0, 1], [0, 0], [0, 0], [0, 0]])\n",
    "y_set = np.array([0, 0, 0, 0, 1, 1, 1, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T00:21:23.040177Z",
     "end_time": "2023-04-16T00:21:23.065113Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T00:21:23.057781Z",
     "end_time": "2023-04-16T00:21:23.072170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 4/8\n",
      "B: 3/8\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# TODO counting_heuristic()\n",
    "correct_list = []\n",
    "sort_names_list = []\n",
    "\n",
    "for feature_num in range(feature_len):\n",
    "    total_correct = counting_heuristic(x_inputs=x_set, y_outputs=y_set, feature_index=feature_num, classes=classes)\n",
    "\n",
    "    correct_list.append(total_correct)\n",
    "    sort_names_list.append(feature_names[feature_num])\n",
    "\n",
    "# TODO sort the feature names by their correct counts\n",
    "# e.g., sort_correct = [best, second_best, ..., worst]\n",
    "# e.g., sort_names = [\"A\", \"B\"] or [\"B\",\"A\"]\n",
    "my_dict = OrderedDict()\n",
    "for correct, name in zip(correct_list, sort_names_list):\n",
    "    my_dict[correct] = name\n",
    "\n",
    "high_to_low = OrderedDict(sorted(my_dict.items(), key=lambda x: x[1]))\n",
    "sort_correct = list(high_to_low.keys()) #TODO: FIX ME\n",
    "sort_names = list(high_to_low.values()) #TODO: FIX ME\n",
    "\n",
    "# Print the sorted features along with their correct predictions count in the smaller dataset\n",
    "longest = max(len(name) for name in sort_names)\n",
    "for name, correct in zip(sort_names, sort_correct):\n",
    "    print(\"%*s: %d/%d\" % (longest, name, correct, len(x_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx = 0 : x_val = array([1, 1])\n",
      "idx = 0 : x_val = array([1, 1]) : entropy = 0.0\n",
      "idx = 0 : x_val = array([1, 1])\n",
      "idx = 0 : x_val = array([1, 1]) : entropy = 0.0\n",
      "idx = 1 : x_val = array([1, 1])\n",
      "idx = 1 : x_val = array([1, 1]) : entropy = 0.0\n",
      "idx = 1 : x_val = array([1, 1])\n",
      "idx = 1 : x_val = array([1, 1]) : entropy = 0.0\n",
      "idx = 2 : x_val = array([0, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[175], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m gains_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m feature_num \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(feature_len):\n\u001B[0;32m----> 6\u001B[0m     gain \u001B[38;5;241m=\u001B[39m \u001B[43minformation_remainder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclasses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclasses\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# gains_list.append(gain)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeature_names[feature_num] \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/CodeProjects/Tufts/CS0135/hw4/src_and_data/implementation.py:68\u001B[0m, in \u001B[0;36minformation_remainder\u001B[0;34m(x_inputs, y_outputs, feature_index, classes)\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;124;03m\"\"\"Calculate the information remainder after splitting the input-output set based on the\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03mgiven feature index.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;124;03m    :return: float, information remainder value\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;66;03m# Calculate the entropy of the overall set\u001B[39;00m\n\u001B[0;32m---> 68\u001B[0m     overall_entropy \u001B[38;5;241m=\u001B[39m \u001B[43mset_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclasses\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;66;03m# Calculate the entropy of each split set\u001B[39;00m\n\u001B[1;32m     71\u001B[0m     set_entropies \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# TODO: fix me\u001B[39;00m\n",
      "File \u001B[0;32m~/CodeProjects/Tufts/CS0135/hw4/src_and_data/implementation.py:49\u001B[0m, in \u001B[0;36mset_entropy\u001B[0;34m(x_inputs, y_outputs, classes)\u001B[0m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx_c, \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(classes):\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx_val \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 49\u001B[0m         entropy \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mx_val[idx_c] \u001B[38;5;241m*\u001B[39m \u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx_c\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx_val \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mentropy \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m entropy\n",
      "\u001B[0;31mValueError\u001B[0m: math domain error"
     ]
    }
   ],
   "source": [
    "# TODO information_remainder()\n",
    "# gains_list = []\n",
    "gains_dict = {}\n",
    "\n",
    "for feature_num in range(feature_len):\n",
    "    gain = information_remainder(x_inputs=x_set, y_outputs=y_set, feature_index=feature_len, classes=classes)\n",
    "    # gains_list.append(gain)\n",
    "    print(f'{feature_names[feature_num] = }')\n",
    "    gains_dict[feature_names[feature_num]] = gain\n",
    "\n",
    "# TODO sort the feature names by their gains\n",
    "gains_sorted = OrderedDict(sorted(my_dict.items(), key=lambda x: x[1]))\n",
    "sort_gains = list(gains_sorted.keys()) #TODO: FIX ME\n",
    "sort_names_by_gains = list(gains_sorted.values()) #TODO: FIX ME\n",
    "\n",
    "longest = max(len(name) for name in sort_names_by_gains)\n",
    "for name, gain in zip(sort_names_by_gains, sort_gains):\n",
    "    print(\"%*s: %.3f\" % (longest, name, gain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discussion of results.\n",
    "\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Compute both heuristics for simplified abalone data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_male', 'length_mm', 'diam_mm', 'height_mm', 'whole_weight_g', 'shucked_weight_g', 'viscera_weight_g', 'shell_weight_g']\n"
     ]
    }
   ],
   "source": [
    "# load the data into np arrays\n",
    "\n",
    "# https://bids.github.io/2015-06-04-berkeley/intermediate-python/03-sklearn-abalone.html\n",
    "\n",
    "# TODO:fix the empty lists below\n",
    "# full-feature abalone data\n",
    "x_train = pd.read_csv('data_abalone/x_train.csv')\n",
    "x_test = pd.read_csv('data_abalone/x_test.csv')\n",
    "y_train = pd.read_csv('data_abalone/y_train.csv')\n",
    "y_test = pd.read_csv('data_abalone/y_test.csv')\n",
    "\n",
    "# TODO:fix the empty lists below\n",
    "# simplified version of the data (Restricted-feature)\n",
    "simple_x_train = pd.read_csv('data_abalone/small_binary_x_train.csv')\n",
    "simple_x_test = pd.read_csv('data_abalone/small_binary_x_test.csv')\n",
    "simple_y_train = pd.read_csv('data_abalone/3class_y_train.csv')\n",
    "simple_y_test = pd.read_csv('data_abalone/3class_y_test.csv')\n",
    "\n",
    "# get useful information\n",
    "# TODO:fix the empty lists below\n",
    "full_feature_names = list(x_test.columns.values) # features names of full-feature abalone data\n",
    "# ['is_male', 'length_mm', 'diam_mm', 'height_mm', 'whole_weight_g', 'shucked_weight_g', 'viscera_weight_g', 'shell_weight_g'] ['rings']\n",
    "\n",
    "simple_feature_names = list(simple_x_test.columns.values) # features names of restricted-feature data\n",
    "# ['is_male', 'length_mm', 'diam_mm', 'height_mm'] ['rings']\n",
    "\n",
    "classes_abalone = [] # unique set of class labels\n",
    "class_names = [] # name of the classes\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T15:53:32.821913Z",
     "end_time": "2023-04-16T15:53:32.848248Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO counting_heuristic()\n",
    "\n",
    "\n",
    "# TODO sort the feature names by their correct counts\n",
    "sort_correct_abalone = []  #TODO: FIX ME\n",
    "sort_names_abalone = [] #TODO: FIX ME\n",
    "\n",
    "# Print the sorted features along with their correct predictions count in the smaller dataset\n",
    "longest = max(len(name) for name in sort_names_abalone)\n",
    "for name, correct in zip(sort_names_abalone, sort_correct_abalone):\n",
    "    print(\"%*s: %d/%d\" % (longest, name, correct, len(simple_x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO information_remainder()\n",
    "\n",
    "# TODO sort the feature names by their gains\n",
    "sort_gains_abalone = []  #TODO: FIX ME\n",
    "sort_names_by_gains_abalone = [] #TODO: FIX ME\n",
    "\n",
    "longest = max(len(name) for name in sort_names_by_gains_abalone)\n",
    "for name, gain in zip(sort_names_by_gains_abalone, sort_gains_abalone):\n",
    "    print(\"%*s: %.3f\" % (longest, name, gain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Generate decision trees (criterion='entropy', random_state=42) for full- and simple-feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) Train and eval on entire train and test sets. Print accuracy values and generate tree images.\n",
    "\n",
    "Render the tree diagram, naming it \"full.\" A text file and PDF should be created and saved (i.e., `full` and `full.pdf`) - include both in submission."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO calculate accuracies\n",
    "train_accuracy = 0 # Fix me\n",
    "test_accuracy = 0 # Fix me\n",
    "print(f\"Accuracy (train): {train_accuracy:.3f}\")\n",
    "print(f\"Accuracy  (test): {test_accuracy:.3f}\")\n",
    "\n",
    "# TODO generate tree image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (b) Restricted-feature (aka simple) data.\n",
    "Train and eval on simple train and test sets. Same as above, accept this time use the `simple` set. Render the tree diagram, naming it \"simple.\" A text file and PDF should be created and saved (i.e., `simple` and `simple.pdf`) - include both in submission."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO calculate out accuracies\n",
    "simple_train_accuracy = 0 # Fix me\n",
    "simple_test_accuracy = 0 # Fix me\n",
    "print(f\"Accuracy (train): {simple_train_accuracy:.3f}\")\n",
    "print(f\"Accuracy  (test): {simple_test_accuracy:.3f}\")\n",
    "\n",
    "# TODO generate tree image\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discuss the results seen for the two trees\n",
    "\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
