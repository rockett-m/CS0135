{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name and ID\n",
    "Morgan Rockett\n",
    "1157051\n",
    "\n",
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW04 Code\n",
    "\n",
    "You will complete the following notebook, as described in the PDF for Homework 04 (included in the download with the starter code).  You will submit:\n",
    "1. This notebook file (`hw04.ipynb`), `implementation.py`, and two files for both trees images, i.e., `full`, `full.pdf`, `simple`, and `simple.pdf` (PDFs and text files generated using `graphviz` within the code). HINT: `render()`, and it should be clear when to use it, i.e., #3). Compress all files mentioned and submit to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/class/lcwv1h9p2a11ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import required libraries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:29.640081Z",
     "end_time": "2023-04-28T16:27:30.205566Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.tree\n",
    "import graphviz\n",
    "\n",
    "from implementation import information_remainder, counting_heuristic, set_entropy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "You should start by computing the two heuristic values for the toy data described in the assignment handout. You should then load the two versions of the abalone data, compute the two heuristic values on features (for the simplified data), and then build decision trees for each set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Compute both heuristics for toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "feature_names = np.array([\"A\", \"B\"])\n",
    "feature_len = 2\n",
    "classes = [0, 1]\n",
    "\n",
    "x_set = np.array([[1, 1], [1, 1], [0, 1], [0, 0], [0, 1], [0, 0], [0, 0], [0, 0]])\n",
    "y_set = np.array([0, 0, 0, 0, 1, 1, 1, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:30.206939Z",
     "end_time": "2023-04-28T16:27:30.223003Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 6/8\n",
      "B: 6/8\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# TODO counting_heuristic()\n",
    "my_dict = OrderedDict()\n",
    "\n",
    "for feature_num in range(feature_len):\n",
    "\n",
    "    total_correct = counting_heuristic(x_inputs=x_set, y_outputs=y_set, feature_index=feature_num, classes=classes)\n",
    "    my_dict[feature_names[feature_num]] = total_correct\n",
    "\n",
    "# TODO sort the feature names by their correct counts\n",
    "# e.g., sort_correct = [best, second_best, ..., worst]\n",
    "# e.g., sort_names = [\"A\", \"B\"] or [\"B\",\"A\"]\n",
    "\n",
    "high_to_low = OrderedDict(sorted(my_dict.items(), key=lambda x: x[1]))\n",
    "sort_correct = list(high_to_low.values()) #TODO: FIX ME\n",
    "sort_names = list(high_to_low.keys()) #TODO: FIX ME\n",
    "# print(f'{sort_correct = }')\n",
    "# print(f'{sort_names = }')\n",
    "# Print the sorted features along with their correct predictions count in the smaller dataset\n",
    "longest = max(len(name) for name in sort_names)\n",
    "for name, correct in zip(sort_names, sort_correct):\n",
    "    print(\"%*s: %d/%d\" % (longest, name, correct, len(x_set)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:30.224368Z",
     "end_time": "2023-04-28T16:27:30.241241Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:30.240908Z",
     "end_time": "2023-04-28T16:27:30.257189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 0.311\n",
      "B: 0.189\n"
     ]
    }
   ],
   "source": [
    "# TODO information_remainder()\n",
    "gains_dict = OrderedDict()\n",
    "\n",
    "for feature_num in range(feature_len):\n",
    "    gain = information_remainder(x_inputs=x_set, y_outputs=y_set, feature_index=feature_num, classes=classes)\n",
    "    gains_dict[feature_names[feature_num]] = gain\n",
    "\n",
    "# TODO sort the feature names by their gains\n",
    "gains_sorted = OrderedDict(sorted(gains_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "sort_gains = list(gains_sorted.values()) #TODO: FIX ME\n",
    "sort_names_by_gains = list(gains_sorted.keys()) #TODO: FIX ME\n",
    "# print(f'{sort_gains = }')\n",
    "# print(f'{sort_names_by_gains = }')\n",
    "\n",
    "longest = max(len(name) for name in sort_names_by_gains)\n",
    "for name, gain in zip(sort_names_by_gains, sort_gains):\n",
    "    print(\"%*s: %.3f\" % (longest, name, gain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discussion of results.\n",
    "\n",
    "Using each of these heuristics, which feature do you choose to start the tree? Explain each choice of feature. How does heuristics affect the tree?\n",
    "\n",
    "Since A and B are equivalent in num correct over the total in the counting-based heuristic and A has a better score (0.311) vs B (0.189) in the information-theoretic heuristic, the tie is broken and A is a better feature to start the tree. Starting the tree is done best by most important features at the top and less prominent features below. If you were to split on less relevant, niche, features at the top, then the decision tree would be more convoluted to view and the tree structure would not be used optimally. Much of its use is for visualization to even non computer science people.\n",
    "\n",
    "If the counting heuristic yielded slightly better results for A and the information gain heuristic gave slightly better results for B this would be a tough decision to make on which feature to start the tree with. Information gain is a stronger way to classify features since the uncertainty level is measured and visible. Choosing one of the two features in each class iteration isn't as good at model building. Starting with feature B would be narrowing the tree too soon in optimal cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Compute both heuristics for simplified abalone data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n# https://bids.github.io/2015-06-04-berkeley/intermediate-python/03-sklearn-abalone.html\\n# TODO:fix the empty lists below\\n# full-feature abalone data\\nx_train_p = pd.read_csv('data_abalone/x_train.csv')\\nx_test_p = pd.read_csv('data_abalone/x_test.csv')\\ny_train_p = pd.read_csv('data_abalone/y_train.csv')\\ny_test_p = pd.read_csv('data_abalone/y_test.csv')\\n# np.loadtxt('data_abalone/x_train.csv')\\n\\n# TODO:fix the empty lists below\\n# simplified version of the data (Restricted-feature)\\nsimple_x_train_p = pd.read_csv('data_abalone/small_binary_x_train.csv')\\nsimple_x_test_p = pd.read_csv('data_abalone/small_binary_x_test.csv')\\nsimple_y_train_p = pd.read_csv('data_abalone/3class_y_train.csv')\\nsimple_y_test_p = pd.read_csv('data_abalone/3class_y_test.csv')\\n\""
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore but helpful for inspecting data in pycharm\n",
    "\"\"\"\n",
    "# https://bids.github.io/2015-06-04-berkeley/intermediate-python/03-sklearn-abalone.html\n",
    "# TODO:fix the empty lists below\n",
    "# full-feature abalone data\n",
    "x_train_p = pd.read_csv('data_abalone/x_train.csv')\n",
    "x_test_p = pd.read_csv('data_abalone/x_test.csv')\n",
    "y_train_p = pd.read_csv('data_abalone/y_train.csv')\n",
    "y_test_p = pd.read_csv('data_abalone/y_test.csv')\n",
    "# np.loadtxt('data_abalone/x_train.csv')\n",
    "\n",
    "# TODO:fix the empty lists below\n",
    "# simplified version of the data (Restricted-feature)\n",
    "simple_x_train_p = pd.read_csv('data_abalone/small_binary_x_train.csv')\n",
    "simple_x_test_p = pd.read_csv('data_abalone/small_binary_x_test.csv')\n",
    "simple_y_train_p = pd.read_csv('data_abalone/3class_y_train.csv')\n",
    "simple_y_test_p = pd.read_csv('data_abalone/3class_y_test.csv')\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:30.258408Z",
     "end_time": "2023-04-28T16:27:30.295660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_feature_names = array(['is_male', 'length_mm', 'diam_mm', 'height_mm', 'whole_weight_g',\n",
      "       'shucked_weight_g', 'viscera_weight_g', 'shell_weight_g'],\n",
      "      dtype='<U16')\n",
      "simple_feature_names = array(['is_male', 'length_mm', 'diam_mm', 'height_mm'], dtype='<U9')\n"
     ]
    }
   ],
   "source": [
    "# load the data into np arrays\n",
    "# TODO:fix the empty lists below\n",
    "# x_train = np.array(np.loadtxt('data_abalone/x_train.csv', delimiter=',', skiprows=1, dtype='float64'))\n",
    "# x_test = np.array(np.loadtxt('data_abalone/x_test.csv', delimiter=',', skiprows=1, dtype='float64'))\n",
    "# y_train = np.array(np.loadtxt('data_abalone/y_train.csv', delimiter=',', skiprows=1, dtype='float64'))\n",
    "# y_test = np.array(np.loadtxt('data_abalone/y_test.csv', delimiter=',', skiprows=1, dtype='float64'))\n",
    "x_train = np.loadtxt('data_abalone/x_train.csv', delimiter=',', skiprows=1)\n",
    "x_test = np.loadtxt('data_abalone/x_test.csv', delimiter=',', skiprows=1)\n",
    "y_train = np.loadtxt('data_abalone/y_train.csv', delimiter=',', skiprows=1)\n",
    "y_test = np.loadtxt('data_abalone/y_test.csv', delimiter=',', skiprows=1)\n",
    "# TODO:fix the empty lists below\n",
    "simple_x_train = np.loadtxt('data_abalone/small_binary_x_train.csv', delimiter=',', skiprows=1)\n",
    "simple_x_test = np.loadtxt('data_abalone/small_binary_x_test.csv', delimiter=',', skiprows=1)\n",
    "simple_y_train = np.loadtxt('data_abalone/3class_y_train.csv', delimiter=',', skiprows=1)\n",
    "simple_y_test = np.loadtxt('data_abalone/3class_y_test.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "full_feature_names = np.array(np.loadtxt('data_abalone/x_train.csv', delimiter=',', max_rows=1, dtype='str'))\n",
    "simple_feature_names = np.loadtxt('data_abalone/small_binary_x_train.csv', delimiter=',', max_rows=1, dtype='str')\n",
    "\n",
    "# get useful information\n",
    "# TODO:fix the empty lists below\n",
    "# full_feature_names = list(x_train.columns.values) # features names of full-feature abalone data\n",
    "# ['is_male', 'length_mm', 'diam_mm', 'height_mm', 'whole_weight_g', 'shucked_weight_g', 'viscera_weight_g', 'shell_weight_g'] ['rings']\n",
    "\n",
    "# simple_feature_names = list(simple_x_train.columns.values) # features names of restricted-feature data\n",
    "# ['is_male', 'length_mm', 'diam_mm', 'height_mm'] ['rings']\n",
    "\n",
    "classes_abalone = [0, 1, 2] # unique set of class labels\n",
    "class_names = ['Small', 'Medium', 'Large'] # name of the classes\n",
    "\n",
    "print(f'{full_feature_names = }')\n",
    "print(f'{simple_feature_names = }')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:30.276492Z",
     "end_time": "2023-04-28T16:27:30.298863Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:30.298070Z",
     "end_time": "2023-04-28T16:27:30.329619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height_mm: 2316/3176\n",
      "  diam_mm: 2266/3176\n",
      "length_mm: 2230/3176\n",
      "  is_male: 1864/3176\n"
     ]
    }
   ],
   "source": [
    "# TODO counting_heuristic()\n",
    "\n",
    "aba_dict = OrderedDict()\n",
    "# for aba_feature in range(len(full_feature_names)):\n",
    "for aba_feature in range(len(simple_feature_names)):\n",
    "\n",
    "    # total_correct_aba = counting_heuristic(x_inputs=x_train, y_outputs=y_train, feature_index=aba_feature, classes=classes_abalone)\n",
    "    total_correct_aba = counting_heuristic(x_inputs=simple_x_train, y_outputs=simple_y_train, feature_index=aba_feature, classes=classes_abalone)\n",
    "\n",
    "    aba_dict[full_feature_names[aba_feature]] = total_correct_aba\n",
    "\n",
    "# TODO sort the feature names by their correct counts\n",
    "high_to_low_aba = OrderedDict(sorted(aba_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "sort_correct_abalone = list(high_to_low_aba.values()) #TODO: FIX ME\n",
    "sort_names_abalone = list(high_to_low_aba.keys()) #TODO: FIX ME\n",
    "\n",
    "# Print the sorted features along with their correct predictions count in the smaller dataset\n",
    "longest = max(len(name) for name in sort_names_abalone)\n",
    "for name, correct in zip(sort_names_abalone, sort_correct_abalone):\n",
    "    print(\"%*s: %d/%d\" % (longest, name, correct, len(simple_x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:30.320112Z",
     "end_time": "2023-04-28T16:27:30.340004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height_mm: 0.173\n",
      "  diam_mm: 0.150\n",
      "length_mm: 0.135\n",
      "  is_male: 0.025\n"
     ]
    }
   ],
   "source": [
    "# TODO information_remainder()\n",
    "info_gains_dict = OrderedDict()\n",
    "for aba_feature in range(len(simple_feature_names)):\n",
    "    gain = information_remainder(x_inputs=simple_x_train, y_outputs=simple_y_train, feature_index=aba_feature, classes=classes_abalone)\n",
    "    info_gains_dict[simple_feature_names[aba_feature]] = gain\n",
    "\n",
    "# TODO sort the feature names by their gains\n",
    "info_gains_sorted = OrderedDict(sorted(info_gains_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "sort_gains_abalone = list(info_gains_sorted.values()) #TODO: FIX ME\n",
    "sort_names_by_gains_abalone = list(info_gains_sorted.keys()) #TODO: FIX ME\n",
    "\n",
    "# longest = max(len(name) for name in sort_names_by_gains_abalone)\n",
    "for name, gain in zip(sort_names_by_gains_abalone, sort_gains_abalone):\n",
    "    print(\"%*s: %.3f\" % (longest, name, gain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Generate decision trees (criterion='entropy', random_state=42) for full- and simple-feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) Train and eval on entire train and test sets. Print accuracy values and generate tree images.\n",
    "\n",
    "Render the tree diagram, naming it \"full.\" A text file and PDF should be created and saved (i.e., `full` and `full.pdf`) - include both in submission."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:30.338804Z",
     "end_time": "2023-04-28T16:27:35.034325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train): 1.000\n",
      "Accuracy  (test): 0.202\n"
     ]
    },
    {
     "data": {
      "text/plain": "'full.pdf'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz\n",
    "\n",
    "full_model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "full_model.fit(X=x_train, y=y_train)\n",
    "\n",
    "train_accuracy = full_model.score(X=x_train, y=y_train)\n",
    "test_accuracy = full_model.score(X=x_test, y=y_test)\n",
    "\n",
    "# TODO calculate accuracies\n",
    "print(f\"Accuracy (train): {train_accuracy:.3f}\")\n",
    "print(f\"Accuracy  (test): {test_accuracy:.3f}\")\n",
    "\n",
    "# TODO generate tree image\n",
    "full_tree = export_graphviz(decision_tree=full_model, feature_names=full_feature_names)\n",
    "generated_graph_full = graphviz.Source(full_tree)\n",
    "generated_graph_full.render('full')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (b) Restricted-feature (aka simple) data.\n",
    "Train and eval on simple train and test sets. Same as above, accept this time use the `simple` set. Render the tree diagram, naming it \"simple.\" A text file and PDF should be created and saved (i.e., `simple` and `simple.pdf`) - include both in submission."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train): 0.733\n",
      "Accuracy  (test): 0.722\n"
     ]
    },
    {
     "data": {
      "text/plain": "'simple.pdf'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz\n",
    "\n",
    "simple_model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "simple_model.fit(X=simple_x_train, y=simple_y_train)\n",
    "\n",
    "# TODO calculate out accuracies\n",
    "simple_train_accuracy = simple_model.score(X=simple_x_train, y=simple_y_train) # Fix me\n",
    "simple_test_accuracy = simple_model.score(X=simple_x_test, y=simple_y_test)  # Fix me\n",
    "\n",
    "print(f\"Accuracy (train): {simple_train_accuracy:.3f}\")\n",
    "print(f\"Accuracy  (test): {simple_test_accuracy:.3f}\")\n",
    "\n",
    "# TODO generate tree image\n",
    "simple_tree = export_graphviz(decision_tree=simple_model, feature_names=simple_feature_names, class_names=class_names)\n",
    "generated_graph_simple = graphviz.Source(simple_tree)\n",
    "generated_graph_simple.render('simple')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:35.035777Z",
     "end_time": "2023-04-28T16:27:35.161433Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discuss the results seen for the two trees\n",
    "\n",
    " Discuss the results you have just seen. What do the various accuracy-score values tell you? How do the two trees that are produced differ? Looking at the outputs (leaves) of the simplified-data tree, what errors does that tree make?\n",
    "\n",
    "The entire sets gave an excellent 1.000 accuracy rating on training data, but on test it was 0.202. This suggests overfitting when the train accuracy is very good but test is poor. The model gets so good at fitting the training data that adapting to unseen data is not successful. The model could be overly complex and it would be better potentially to have a lower-degree polynomial equation for lesser complexity and avoiding overfitting. There are 8 input features for the full feature data but only 4 for the simple data.\n",
    "\n",
    "The simple sets had very comparable accuracy for training and testing at 0.733 and 0.722, respectively. The almost identical accuracies show consistency. The model is predictable. Although the train accuracy is not as high as the full feature data, it is better than a nearly 80% accuracy gap. Low 70s percent accuracy leaves something to be desired, as 90+ percent is ideal; however. The complexity of this model was appropriate given the similar training and testing fits. A reason why the accuracy wasn't as good as it perhaps could have been is the unused \"Large\" class. If we just had \"Small\" and \"Medium\" classes like the simple.pdf shows, then I expect accuracy would be better. Complexity is only good if it improves model performance.\n",
    "\n",
    "Poor accuracy on simple and overfitting on full suggests that we might want to use a different classifier and training method instead of Decision Trees. Alternatively we could try using different criterion types to see if that would boost accuracy.\n",
    "\n",
    "Seeing entropy values greater than 1.0 suggest high levels of disorder and uncertainty. Those leaves on the simple and full graphs alike mean low confidence in the classified results. On the other hand, the many entropy values close to 0.0 or 0.0 in the full graph show high accuracy, which is reflected from the training results. A strategy to build a better full test accuracy would be to reduce the number of full feature train columns to target high 80's accuracy or low 90's accuracy on train and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:27:35.161833Z",
     "end_time": "2023-04-28T16:27:35.166229Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
