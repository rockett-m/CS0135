{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnYtaTBab9ehgASuYf1b4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rockett-m/CS0135/blob/main/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jtCDJz_I0pKC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A coding assignment that combines splitting data into train, test, and validation sets using scikit-learn (sklearn):\n",
        "\n",
        "Problem Statement:\n",
        "\n",
        "You are given a dataset containing information about different types of iris flowers (sepal length, sepal width,\n",
        "petal length, and petal width). Your task is to build a machine learning model to classify the iris flowers into\n",
        "three different classes (setosa, versicolor, virginica) based on their physical characteristics.\n",
        "\n",
        "You are to do the following:\n",
        "Step 1: Load the iris dataset\n",
        "    Use the following code to load the iris dataset into a pandas dataframe:\n",
        "\n",
        "Step 2: Split the data into training, validation, and test sets\n",
        "    Use the following code to split the data into training (60%), validation (20%), and test (20%) sets:\n",
        "\n",
        "Step 3: Train a classifier (this function is provided for you)\n",
        "    Use the following code to train a support vector machine (SVM) classifier on the training set:\n",
        "\n",
        "Step 4: Evaluate the model on the validation set\n",
        "    Use the following code to evaluate the performance of the trained classifier on the validation set:\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "Step 5: Evaluate the model on the test set\n",
        "    Use the following code to evaluate the performance of the trained classifier on the test set:\n",
        "\n",
        "This assignment is designed to help you understand the basics of splitting data into train, validation, and test sets,\n",
        "as well as training a simple machine learning model using scikit-learn. The assignment can be extended by trying\n",
        "different classifiers, tuning the parameters, or exploring the dataset further.\n",
        "\n",
        "Step 6: Then, do the same for K-Fold cross validation.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attribute Information:\n",
        "\n",
        "1. sepal length in cm\n",
        "2. sepal width in cm\n",
        "3. petal length in cm\n",
        "4. petal width in cm\n",
        "5. class:\n",
        "-- Iris Setosa  \n",
        "-- Iris Versicolour  \n",
        "-- Iris Virginica  \n",
        "https://archive.ics.uci.edu/ml/datasets/iris"
      ],
      "metadata": {
        "id": "AVKFPzuF2AZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "'feature_names' = list\n",
        "['sepal length (cm)',\n",
        " 'sepal width (cm)',\n",
        " 'petal length (cm)',\n",
        " 'petal width (cm)']\n",
        "\n",
        "'target_names' =\n",
        " array(['setosa', 'versicolor', 'virginica'],\n"
      ],
      "metadata": {
        "id": "CIYcuIRP6kXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the iris dataset and return it as a pandas dataframe\n",
        "\n",
        "Returns:\n",
        "    df_out (pandas dataframe): The iris dataset\n",
        "\"\"\"\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#TODO load data, convert to dataframe, and return\n",
        "iris = load_iris()\n",
        "print(type(iris))\n",
        "print(iris.items, len(iris))\n",
        "\n",
        "for elem in iris:\n",
        "    print(f'{elem = }')\n",
        "\n",
        "# print(f'{iris.data = }')\n",
        "# print(f'{iris.data = }')\n",
        "data = iris.data # (150, 4)\n",
        "target = iris.target # (150,)\n",
        "target_names = iris.target_names # (3,)\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# df_data = pd.DataFrame(data=iris.data)\n",
        "\n",
        "# test data does not change! (20%)\n",
        "# 80% to training\n",
        "# take 20% of training data into val data\n",
        "# call split twice !!!\n",
        "# test = df_data[len(df_data):]  # 80% to the end\n",
        "\n",
        "# X - data\n",
        "# X_data = iris.data[:][:]\n",
        "# Y_data = iris.data[:][1]\n",
        "# Y - target\n",
        "# target\n",
        "\n",
        "# df_data.head()\n",
        "# df_data.describe()\n",
        "\n",
        "# iris\n",
        "# iris.info()\n",
        "# print(iris)\n",
        "# df = pd.read()\n",
        "# return df_data\n",
        "# pass\n",
        "\"\"\"\n",
        "Classes: 3\n",
        "Samples per class: 50\n",
        "Samples total: 150\n",
        "Dimensionality: 4\n",
        "Features: real, positive\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "zAMEANZK4kxR",
        "outputId": "1b98d55f-1693-4866-84ad-8b5262760595"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n",
            "<built-in method items of Bunch object at 0x7f0c40255680> 8\n",
            "elem = 'data'\n",
            "elem = 'target'\n",
            "elem = 'frame'\n",
            "elem = 'target_names'\n",
            "elem = 'DESCR'\n",
            "elem = 'feature_names'\n",
            "elem = 'filename'\n",
            "elem = 'data_module'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nClasses: 3\\nSamples per class: 50\\nSamples total: 150\\nDimensionality: 4\\nFeatures: real, positive\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load the iris dataset and return it as a pandas dataframe\n",
        "\n",
        "    Returns:\n",
        "        df_out (pandas dataframe): The iris dataset\n",
        "    \"\"\"\n",
        "    from sklearn.datasets import load_iris\n",
        "\n",
        "    #TODO load data, convert to dataframe, and return\n",
        "    iris = load_iris()\n",
        "    df_data = pd.DataFrame(iris.data)\n",
        "    # df_data.head()\n",
        "    # df_data.describe()\n",
        "\n",
        "    # iris\n",
        "    # iris.info()\n",
        "    # print(iris)\n",
        "    # df = pd.read()\n",
        "    return df_data\n",
        "    # pass"
      ],
      "metadata": {
        "id": "YuDWJlng1VLa"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(df_in):\n",
        "    \"\"\"\n",
        "    Split the data into training, validation, and test sets\n",
        "\n",
        "    Parameters:\n",
        "    df_in (pandas dataframe): The iris dataset\n",
        "\n",
        "    Returns:\n",
        "    X_train_out (numpy array): Training set features\n",
        "    X_val_out (numpy array): Validation set features\n",
        "    X_test_out (numpy array): Test set features\n",
        "    y_train_out (numpy array): Training set targets\n",
        "    y_val_out (numpy array): Validation set targets\n",
        "    y_test_out (numpy array): Test set targets\n",
        "    \"\"\"\n",
        "    # TODO split train and test, and then split train and val\n",
        "    x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.20)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25)\n",
        "    # X_train_out = X_val_out = X_test_out = y_train_out = y_val_out = y_test_out = np.float(0)\n",
        "\n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test"
      ],
      "metadata": {
        "id": "7i7qv9bD1b0l"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(X_train_in, y_train_in):\n",
        "    \"\"\"\n",
        "    Train a support vector machine (SVM) classifier on the training set\n",
        "\n",
        "    Parameters:\n",
        "    X_train_in (numpy array): Training set features\n",
        "    y_train_in (numpy array): Training set targets\n",
        "\n",
        "    Returns:\n",
        "    clf_out (SVM classifier): Trained SVM classifier\n",
        "    \"\"\"\n",
        "    clf_out = SVC(kernel='linear', C=1, random_state=0)\n",
        "    clf_out.fit(X_train_in, y_train_in)\n",
        "\n",
        "    return clf_out"
      ],
      "metadata": {
        "id": "2U9hFRJO0xKo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(clf, X, y):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of the trained classifier on a given set\n",
        "\n",
        "    Parameters:\n",
        "    clf (SVM classifier): Trained SVM classifier\n",
        "    X (numpy array): Features of the set to evaluate the classifier on\n",
        "    y (numpy array): Targets of the set to evaluate the classifier on\n",
        "\n",
        "    Returns:\n",
        "    accuracy_out (float): Accuracy of the classifier on the given set\n",
        "    \"\"\"\n",
        "    # TODO evaluate the model on data\n",
        "    accuracy_test_out = clf.score(X, y)\n",
        "\n",
        "    return accuracy_test_out"
      ],
      "metadata": {
        "id": "bl08M4k71lYj"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_cross_validation(df, k=5):\n",
        "    \"\"\"\n",
        "    Perform k-fold cross validation on the iris dataset\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas dataframe): The iris dataset\n",
        "    k (int, optional): The number of folds. Default is 5.\n",
        "\n",
        "    Returns:\n",
        "    accuracy_out (list): A list of accuracy_out scores for each fold\n",
        "    \"\"\"\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    # TODO do 5-fold on dataset and return the accuracy across the five folds\n",
        "    clf_out = SVC(kernel='linear', C=1, random_state=0)\n",
        "    accuracy_five_folds = cross_val_score(clf_out, X=iris.data, y=iris.target, cv=k, scoring=\"accuracy\")\n",
        "\n",
        "    return accuracy_five_folds"
      ],
      "metadata": {
        "id": "Wv6QIIz71nm9"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load the iris dataset\n",
        "    df_data = load_data()\n",
        "\n",
        "    # Train, Val, Test\n",
        "    # Split the data into training, validation, and test sets\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df_data) \n",
        "    # test data does not change! (20%)\n",
        "    # 80% to training\n",
        "    # take 20% of training data into val data\n",
        "    # call split twice !!!\n",
        "\n",
        "    # Train a classifier\n",
        "    clf = train_classifier(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    accuracy_val = evaluate_model(clf, X_val, y_val)\n",
        "    print(\"Accuracy on validation set:\", accuracy_val)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    accuracy_test = evaluate_model(clf, X_test, y_test)\n",
        "    print(\"Accuracy on test set:\", accuracy_test)\n",
        "\n",
        "    # K-FOLD\n",
        "    # Perform k-fold cross validation\n",
        "    accuracy = k_fold_cross_validation(df_data)\n",
        "\n",
        "    # Print the accuracy scores for each fold\n",
        "    for i, acc in enumerate(accuracy):\n",
        "        print(\"Accuracy on fold\", i + 1, \":\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zj8idL21pWL",
        "outputId": "24c15144-d5cd-4a9b-a408-079e719c28e2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on validation set: 1.0\n",
            "Accuracy on test set: 0.9666666666666667\n",
            "Accuracy on fold 1 : 0.9666666666666667\n",
            "Accuracy on fold 2 : 1.0\n",
            "Accuracy on fold 3 : 0.9666666666666667\n",
            "Accuracy on fold 4 : 0.9666666666666667\n",
            "Accuracy on fold 5 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQQ606PQ2YCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}