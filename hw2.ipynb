{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpepxlh80na9pwdCHD4WAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rockett-m/CS0135/blob/main/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jtCDJz_I0pKC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A coding assignment that combines splitting data into train, test, and validation sets using scikit-learn (sklearn):\n",
        "\n",
        "Problem Statement:\n",
        "\n",
        "You are given a dataset containing information about different types of iris flowers (sepal length, sepal width,\n",
        "petal length, and petal width). Your task is to build a machine learning model to classify the iris flowers into\n",
        "three different classes (setosa, versicolor, virginica) based on their physical characteristics.\n",
        "\n",
        "You are to do the following:\n",
        "Step 1: Load the iris dataset\n",
        "    Use the following code to load the iris dataset into a pandas dataframe:\n",
        "\n",
        "Step 2: Split the data into training, validation, and test sets\n",
        "    Use the following code to split the data into training (60%), validation (20%), and test (20%) sets:\n",
        "\n",
        "Step 3: Train a classifier (this function is provided for you)\n",
        "    Use the following code to train a support vector machine (SVM) classifier on the training set:\n",
        "\n",
        "Step 4: Evaluate the model on the validation set\n",
        "    Use the following code to evaluate the performance of the trained classifier on the validation set:\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "Step 5: Evaluate the model on the test set\n",
        "    Use the following code to evaluate the performance of the trained classifier on the test set:\n",
        "\n",
        "This assignment is designed to help you understand the basics of splitting data into train, validation, and test sets,\n",
        "as well as training a simple machine learning model using scikit-learn. The assignment can be extended by trying\n",
        "different classifiers, tuning the parameters, or exploring the dataset further.\n",
        "\n",
        "Step 6: Then, do the same for K-Fold cross validation.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attribute Information:\n",
        "\n",
        "1. sepal length in cm\n",
        "2. sepal width in cm\n",
        "3. petal length in cm\n",
        "4. petal width in cm\n",
        "5. class:\n",
        "-- Iris Setosa  \n",
        "-- Iris Versicolour  \n",
        "-- Iris Virginica  \n",
        "https://archive.ics.uci.edu/ml/datasets/iris"
      ],
      "metadata": {
        "id": "AVKFPzuF2AZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the iris dataset and return it as a pandas dataframe\n",
        "\n",
        "Returns:\n",
        "    df_out (pandas dataframe): The iris dataset\n",
        "\"\"\"\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#TODO load data, convert to dataframe, and return\n",
        "iris = load_iris()\n",
        "print(type(iris))\n",
        "print(iris.items, len(iris))\n",
        "\n",
        "for elem in iris:\n",
        "    print(f'{elem = }')\n",
        "\n",
        "# df_data = pd.DataFrame(iris)\n",
        "# df_data.head()\n",
        "# df_data.describe()\n",
        "\n",
        "# iris\n",
        "# iris.info()\n",
        "# print(iris)\n",
        "# df = pd.read()\n",
        "# return df_data\n",
        "# pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAMEANZK4kxR",
        "outputId": "8f49cf60-905c-48a8-8d40-6bd27b47f68f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n",
            "<built-in method items of Bunch object at 0x7f519b42b3b0> 8\n",
            "elem = 'data'\n",
            "elem = 'target'\n",
            "elem = 'frame'\n",
            "elem = 'target_names'\n",
            "elem = 'DESCR'\n",
            "elem = 'feature_names'\n",
            "elem = 'filename'\n",
            "elem = 'data_module'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load the iris dataset and return it as a pandas dataframe\n",
        "\n",
        "    Returns:\n",
        "        df_out (pandas dataframe): The iris dataset\n",
        "    \"\"\"\n",
        "    from sklearn.datasets import load_iris\n",
        "\n",
        "    #TODO load data, convert to dataframe, and return\n",
        "    iris, boole = load_iris()\n",
        "    df_data = pd.DataFrame(iris)\n",
        "    df_data.head()\n",
        "    df_data.describe()\n",
        "\n",
        "    # iris\n",
        "    # iris.info()\n",
        "    # print(iris)\n",
        "    # df = pd.read()\n",
        "    return df_data\n",
        "    # pass"
      ],
      "metadata": {
        "id": "YuDWJlng1VLa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(df_in):\n",
        "    \"\"\"\n",
        "    Split the data into training, validation, and test sets\n",
        "\n",
        "    Parameters:\n",
        "    df_in (pandas dataframe): The iris dataset\n",
        "\n",
        "    Returns:\n",
        "    X_train_out (numpy array): Training set features\n",
        "    X_val_out (numpy array): Validation set features\n",
        "    X_test_out (numpy array): Test set features\n",
        "    y_train_out (numpy array): Training set targets\n",
        "    y_val_out (numpy array): Validation set targets\n",
        "    y_test_out (numpy array): Test set targets\n",
        "    \"\"\"\n",
        "    # TODO split train and test, and then split train and val\n",
        "    pass"
      ],
      "metadata": {
        "id": "7i7qv9bD1b0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(X_train_in, y_train_in):\n",
        "    \"\"\"\n",
        "    Train a support vector machine (SVM) classifier on the training set\n",
        "\n",
        "    Parameters:\n",
        "    X_train_in (numpy array): Training set features\n",
        "    y_train_in (numpy array): Training set targets\n",
        "\n",
        "    Returns:\n",
        "    clf_out (SVM classifier): Trained SVM classifier\n",
        "    \"\"\"\n",
        "    clf_out = SVC(kernel='linear', C=1, random_state=0)\n",
        "    clf_out.fit(X_train_in, y_train_in)\n",
        "\n",
        "    return clf_out"
      ],
      "metadata": {
        "id": "2U9hFRJO0xKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluate_model(clf, X, y):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of the trained classifier on a given set\n",
        "\n",
        "    Parameters:\n",
        "    clf (SVM classifier): Trained SVM classifier\n",
        "    X (numpy array): Features of the set to evaluate the classifier on\n",
        "    y (numpy array): Targets of the set to evaluate the classifier on\n",
        "\n",
        "    Returns:\n",
        "    accuracy_out (float): Accuracy of the classifier on the given set\n",
        "    \"\"\"\n",
        "    # TODO evaluate the model on data\n",
        "    pass"
      ],
      "metadata": {
        "id": "bl08M4k71lYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def k_fold_cross_validation(df, k=5):\n",
        "    \"\"\"\n",
        "    Perform k-fold cross validation on the iris dataset\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas dataframe): The iris dataset\n",
        "    k (int, optional): The number of folds. Default is 5.\n",
        "\n",
        "    Returns:\n",
        "    accuracy_out (list): A list of accuracy_out scores for each fold\n",
        "    \"\"\"\n",
        "    # TODO do 5-fold on dataset and return the accuracy across the five folds\n",
        "    pass"
      ],
      "metadata": {
        "id": "Wv6QIIz71nm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load the iris dataset\n",
        "    df_data = load_data()\n",
        "\n",
        "    # Train, Val, Test\n",
        "    # Split the data into training, validation, and test sets\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df_data)\n",
        "\n",
        "    # Train a classifier\n",
        "    clf = train_classifier(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    accuracy_val = evaluate_model(clf, X_val, y_val)\n",
        "    print(\"Accuracy on validation set:\", accuracy_val)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    accuracy_test = evaluate_model(clf, X_test, y_test)\n",
        "    print(\"Accuracy on test set:\", accuracy_test)\n",
        "\n",
        "    # K-FOLD\n",
        "    # Perform k-fold cross validation\n",
        "    accuracy = k_fold_cross_validation(df_data)\n",
        "\n",
        "    # Print the accuracy scores for each fold\n",
        "    for i, acc in enumerate(accuracy):\n",
        "        print(\"Accuracy on fold\", i + 1, \":\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5Zj8idL21pWL",
        "outputId": "ba2f801d-88c3-4269-99d6-3648900abfa7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d349681d363d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load the iris dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Train, Val, Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-40364cb07abd>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#TODO load data, convert to dataframe, and return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQQ606PQ2YCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}