<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags always come first -->
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>HW2: Evaluating Binary Classifiers and Implementing Logistic Regression | Introduction to Machine Learning
</title>
  <link rel="canonical" href="https://www.cs.tufts.edu/comp/135/2020f/hw2.html">



  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  <script src="https://www.cs.tufts.edu/comp/135/2020f/theme/js/icsFormatter.js"></script>

  <link rel="stylesheet" href="https://www.cs.tufts.edu/comp/135/2020f/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://www.cs.tufts.edu/comp/135/2020f/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://www.cs.tufts.edu/comp/135/2020f/theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="https://www.cs.tufts.edu/comp/135/2020f/theme/css/style.css">
  <link rel="stylesheet" href="https://www.cs.tufts.edu/comp/135/2020f/theme/css/custom.css">


<meta name="description" content="Status: RELEASED. Due date: Wed. Oct. 14 at 11:59PM AoE (Anywhere on Earth) (Thu 10/14 at 07:59am in Boston) Updates 2020-10-01 : Instructions for Report Short Answer 1a clarified: use the test set. 2020-10-05 : Instructions for Coding Task 2(c) clarified: make sure you use the base-2 logarithm …">
</head>

<body>
  <header class="header">
    <nav class="navbar navbar-expand-lg navbar-expand-md navbar-light bg-light">
    <div class="container">
    <div class="row display-flex">
        <div class="col-2 col-sm-2 d-md-none"><!-- hidden if md or lg -->
        <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#my_collapsing_navbar"
            aria-controls="my_collapsing_navbar"
            aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon mw-100"></span>
        </button>
        </div>

        <div class="d-none d-md-block col-md-2">
          <a href="https://www.cs.tufts.edu/comp/135/2020f/">
            <img class="img-fluid mw-100" src=https://www.cs.tufts.edu/comp/135/2020f/images/tufts_ml_logo.png alt="Introduction to Machine Learning">
          </a>
        </div>

        <div class="col-10 col-sm-10 col-md-10">
          <h1 class="text-left" style="word-break:'break-all'">
            <a href="https://www.cs.tufts.edu/comp/135/2020f/">Introduction to Machine Learning</a>
          </h1>

          <p class="text-muted text-left d-none d-md-block mw-100">
            Tufts CS COMP 135 Intro ML | Fall 2020
          </p>



          <div class="collapse navbar-collapse" id="my_collapsing_navbar">
                <ul class="navbar-nav">
                  <li class="nav-item text-left">
                    <a href="index.html">Syllabus</a>
                  </li>
                  <li class="nav-item text-left">
                    <a href="schedule.html">Schedule</a>
                  </li>
                  <li class="nav-item text-left">
                    <a href="assignments.html">Assignments</a>
                  </li>
                  <li class="nav-item text-left">
                    <a href="office_hours.html">Office Hours</a>
                  </li>
                  <li class="nav-item text-left">
                    <a href="resources.html">Resources</a>
                  </li>

                </ul>
          </div>


        </div>

    </div>
    </div>
    </nav>

  </header>

  <div class="main">
    <div class="container">
      <h1>HW2: Evaluating Binary Classifiers and Implementing Logistic Regression
</h1>
      <hr>
<article class="article">
  <div class="content">
        <p style="text-align:right">Last modified: 2020-10-21 11:25 </p>
    <p><strong>Status: RELEASED.</strong></p>
<p><strong>Due date</strong>: Wed. Oct. 14 at 11:59PM AoE (Anywhere on Earth) (Thu 10/14 at 07:59am in Boston)</p>
<h2>Updates</h2>
<ul>
<li>2020-10-01 : Instructions for Report Short Answer 1a clarified: use the <em>test</em> set.</li>
<li>2020-10-05 : Instructions for Coding Task <a href="#2c">2(c)</a> clarified: make sure you use the <em>base-2</em> logarithm for all returned values.</li>
<li>2020-10-09 : Clarified <a href="#selecting_thresh">Selecting the Decision Threshold</a> step, please consider the candidate thresholds produced by starter code helper function when you do your search</li>
<li>2020-10-14 : Clarified for <a href="#problem-1e">Short answer 1e</a> what the current practice is you compare your method to, and that you can assume that the test set represents your population.</li>
</ul>
<h2>Overview</h2>
<p>In this HW, you'll complete the following:</p>
<ul>
<li>First, complete <em>Problem 1's code tasks</em>, writing Python code based on provided starter code. You'll submit your code as a ZIP to the autograder link below.</li>
<li>Second, for Problem 1, complete some <em>analysis</em> tasks and write a <em>report</em>. You'll submit this PDF report separately.</li>
<li>Third, complete <em>Problem 2's code tasks</em>, writing Python code based on provided starter code. Again, you'll submit your code as a ZIP to the autograder link below.</li>
</ul>
<p>As much as possible, we have tried to decouple these parts, so you may successfully complete the report even if some of your code doesn't work. Much of your analysis will use library code in sklearn with similar functionality as what you implement yourself.</p>
<p><strong>Turn-in links</strong>:</p>
<ul>
<li>PDF report turned in to: <a href="https://www.gradescope.com/courses/173055/assignments/697950/">https://www.gradescope.com/courses/173055/assignments/697950/</a></li>
<li>ZIP file of source code turned in to: <a href="https://www.gradescope.com/courses/173055/assignments/697944">https://www.gradescope.com/courses/173055/assignments/697944</a></li>
<li>Finally, complete your reflection here: <a href="https://forms.gle/HKBRZH3Y3H291u4h9">https://forms.gle/HKBRZH3Y3H291u4h9</a></li>
<li>
<ul>
<li>Reflection requires a <code>tufts.edu</code> G-Suite account: <a href="http://systems.eecs.tufts.edu/logging-into-g-suite/">http://systems.eecs.tufts.edu/logging-into-g-suite/</a></li>
</ul>
</li>
</ul>
<p><strong>Files to Turn In:</strong></p>
<p>PDF report:</p>
<ul>
<li>Prepare a short PDF report (no more than 5 pages; ideally 1 page per problem below).</li>
<li>This document will be manually graded.</li>
<li>Can use your favorite report writing tool (Word or G Docs or LaTeX or ....)</li>
<li>Should be <strong>human-readable</strong>. Do not include code. Do NOT just export a jupyter notebook to PDF.</li>
<li>Should have each subproblem <a href="https://www.youtube.com/watch?v=KMPoby5g_nE&amp;feature=youtu.be&amp;t=43">marked via the in-browser Gradescope annotation tool</a>)</li>
</ul>
<p>ZIP file of source code submitted to autograder should contain:</p>
<ul>
<li>performance_metrics_for_binary_predictions.py (will be autograded)</li>
<li>performance_metrics_for_proba_predictions.py (will be autograded)</li>
<li>logsumexp.py (will be autograded)</li>
<li>hw2.ipynb (just for completeness, will not be autograded and will be manually assessed only if necessary.)</li>
</ul>
<p><strong>Evaluation Rubric:</strong></p>
<p>See the PDF submission portal on Gradescope for the point values of each problem. Generally, tasks with more coding/effort will earn more potential points.</p>
<p><strong>Jump to</strong>: 
<a href="#code-tasks">Code Tasks</a> &nbsp; <a href="#starter-code">Starter Code</a> &nbsp; <a href="#dataset">Dataset</a> &nbsp;
<a href="#problem-1">Problem 1</a> &nbsp; <a href="#problem-2">Problem 2</a></p>
<h2>Background</h2>
<p>To complete this HW, you'll need some specific knowledge from the following sessions of class:</p>
<ul>
<li>Gradient Descent (day06)</li>
<li>Evaluation of Binary Classifiers (day07)</li>
<li>Logistic Regression (day08)</li>
</ul>
<h4><a name="starter-code"> Starter Code </a></h4>
<p>See the hw2 folder of the public assignments repo for this class:</p>
<p><a href="https://github.com/tufts-ml-courses/comp135-20f-assignments/tree/master/hw2">https://github.com/tufts-ml-courses/comp135-20f-assignments/tree/master/hw2</a></p>
<p>This starter code includes several <code>.py</code> files for core functionality you need to implement yourself.</p>
<p>It also includes a notebook to help you organize your analysis.</p>
<h2><a name="problem-1"> Problem 1: Binary Classifier for Cancer-Risk Screening </a></h2>
<h4><a name="code-task-1"> Code Tasks for Problem 1: </a> Implement performance metrics for binary predictions</h4>
<p>Here, you'll implement several metrics for comparing provided "true" binary labels with "predicted" binary decisions.</p>
<p>See the starter code file: <a href="https://github.com/tufts-ml-courses/comp135-20f-assignments/blob/master/hw2/performance_metrics_for_binary_predictions.py">performance_metrics_for_binary_predictions.py</a>.</p>
<p><strong> Task 1(a) </strong> : Implement <code>calc_TP_TN_FP_FN</code></p>
<p><strong> Task 1(b) </strong> : Implement <code>calc_ACC</code></p>
<p><strong> Task 1(c) </strong> : Implement <code>calc_TPR</code> and <code>calc_TNR</code></p>
<p><strong> Task 1(d) </strong> : Implement <code>calc_PPV</code> and <code>calc_NPV</code></p>
<p>See the starter code for example inputs and the expected output.</p>
<h4><a name="dataset"> Dataset: Predicting Cancer Risk from Easy-to-measure Facts </a></h4>
<p>You have been given a dataset containing some medical history information for 750 patients that might be at risk of cancer. Dataset credit: A. Vickers, Memorial Sloan Kettering Cancer Center <a href="https://www.mskcc.org/sites/default/files/node/4509/documents/dca-tutorial-2015-2-26.pdf">[original link]</a>.</p>
<p>Each patient in our dataset has been biopsied (fyi: in this case a <a href="https://www.cancer.net/navigating-cancer-care/diagnosing-cancer/tests-and-procedures/biopsy">biopsy</a> is a short surgical procedure that is painful but with virtually no lasting harmful effects) to obtain a direct "ground truth" label so we know each patient's actual cancer status (binary variable, 1 means "has cancer", 0 means does not, column name is <code>cancer</code> in the <span class="math">\(y\)</span> data files). We want to build classifiers to predict whether a patient likely has cancer from easier-to-get information, so we could avoid painful biopsies unless they are necessary. Of course, if we skip the biopsy, a patient with cancer would be left undiagnosed and therefore untreated. We're told by the doctors this outcome would be life-threatening.</p>
<p><em>Easiest</em> features: It is known that older patients with a family history of cancer have a higher probability of harboring cancer. So we can use <code>age</code> and <code>famhistory</code> variables  in the <span class="math">\(x\)</span> dataset files as inputs to a simple predictor.</p>
<p><em>Possible new feature</em>: A clinical chemist has recently discovered a real-valued marker (called <code>marker</code> in the <span class="math">\(x\)</span> dataset files) that she believes can distinguish between patients with and without cancer. We wish to assess whether or not the new marker does indeed identify patients with and without cancer well. </p>
<p>To summarize, there are two versions of the features <span class="math">\(x\)</span> we'd like you to examine:</p>
<ul>
<li>2-feature dataset: 'age' and 'famhistory'</li>
<li>3-feature dataset: 'marker', 'age' and 'famhistory'</li>
</ul>
<p><em>Bottom-line</em>: We are building classifiers so that many patients might not need to undergo a painful biopsy if our classifier is reliable enough to be trusted to filter out low-risk patients.</p>
<p>In the starter code, we have provided an existing train/validation/test split of this dataset, stored on-disk in comma-separated-value (CSV) files: x_train.csv, y_train.csv, x_valid.csv, y_valid.csv, x_test.csv, and y_test.csv.  </p>
<p>Get the data here: <a href="https://github.com/tufts-ml-courses/comp135-20f-assignments/tree/master/hw2/data_cancer">https://github.com/tufts-ml-courses/comp135-20f-assignments/tree/master/hw2/data_cancer</a></p>
<h4>Understanding the Dataset</h4>
<p><strong> Implementation Step 1A </strong>
Given the provided datasets (as CSV files), load them and compute the relevant counts needed for Table 1A below.</p>
<p><strong> Table 1 in Report </strong></p>
<p>Provide a table summarizing some basic properties of the provided training set, validation set, and test set:</p>
<ul>
<li>Row 1 'total count': how many total examples are in each set, total?</li>
<li>Row 2 'positive label count': how many examples have a positive label (means cancer)?</li>
<li>Row 3 'fraction positive' : what fraction (between 0 and 1) of the examples have cancer?</li>
</ul>
<h4>Establishing Baseline Prediction Quality</h4>
<p><strong> Implementation Step 1B </strong></p>
<p>Given a training set of values <span class="math">\(\{y_n \}_{n=1}^N\)</span>, we can <strong>always</strong> consider a simple baseline for prediction that returns the same constant predicted label regardless of the input <span class="math">\(x_i\)</span> feature vector:</p>
<ul>
<li>predict-0-always : <span class="math">\(\forall i, \quad \hat{y}(x_i) = 0\)</span></li>
</ul>
<p>Compute the confusion matrix for this baseline classifier, and save it for later (see Table 2 below).</p>
<p><strong> Short Answer 1a in Report </strong>
What <em>accuracy</em> does the "predict-0-always" classifier get on the <em>test</em> set (report to 3 decimal places)?
(You should see a pretty good number). Does this mean we should use this classifier?</p>
<p><strong> Short Answer 1b in Report </strong></p>
<p>Consider a general binary classifier for this task (not just the baseline above, but any classifier). For the intended application (screening patients before biopsy), describe the possible mistakes the classifier can make in task-specific terms. What costs does each mistake entail (lost time? lost money? life-threatening harm?). </p>
<p><strong> Short Answer 1c in Report </strong> (<em>Note: Added after turn in so next time will be more clear.</em>)</p>
<p>How do you recommend evaluating a potential classifier to be mindful of these costs?</p>
<h4>Trying Logistic Regression: Training and Hyperparameter Selection</h4>
<p><strong> Implementation Step 1C </strong></p>
<p>Consider the <em>2-feature</em> dataset. Fit a logistic regression model using sklearn's <code>LogisticRegression</code> implementation <code>sklearn.linear_model.LogisticRegression</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">docs</a>.</p>
<p>When you construct your <code>LogisticRegression</code> classifier, please be sure that:</p>
<ul>
<li>Set <code>solver='lbfgs'</code> (ensures consistent performance, coherent penalty)</li>
<li>Provide a positive value for hyperparameter <code>C</code>, an "inverse strength value" for the L2 penalty on coefficient weights</li>
<li>
<ul>
<li>Small C (e.g. <span class="math">\(10^{-6}\)</span>) mean the weights should be near zero (equivalent to large <span class="math">\(\alpha\)</span>)</li>
</ul>
</li>
<li>
<ul>
<li>Large C (e.g. <span class="math">\(10^{+6}\)</span>) means the weights should be unpenalized (equivalent to small <span class="math">\(\alpha\)</span>)</li>
</ul>
</li>
</ul>
<p>To avoid overfitting, you should explore a range of <code>C</code> values, using a regularly-spaced grid: <code>C_grid = np.logspace(-9, 6, 31)</code>. Among these possible values, select the value that minimizes the <em>mean cross entropy loss</em> on the <em>validation set</em>. The starter code contains a function from sklearn for computing this loss. Later in Problem 2, you'll implement this loss yourself.</p>
<p><strong> Implementation Step 1D </strong></p>
<p>Repeat 1C, for the <em>3-feature</em> dataset.</p>
<h4>Comparing Models with ROC Analysis</h4>
<p>We have trained two possible LR models, one using the 2-feature dataset (<span class="math">\(F=2\)</span>) and the other with the 3-feature dataset (<span class="math">\(F=3\)</span>).
Which is better?</p>
<p>Receiver Operating Curves ("ROC" curves) allow us to compare classifiers <em>across many possible decision thresholds</em>. Each curve shows the tradeoffs a classifier makes between true positive rate (TPR) and false positive rate (FPR), as you vary the decision threshold.
Remember FPR = 1 - TNR.</p>
<p>You can use `sklearn.metrics.roc_curve' to plot such curves. To understand how to use this function, consult the function's <a href="https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc">User Guide</a> and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve">documentation</a>.</p>
<p><strong> Figure 1 in Report </strong></p>
<p>Compare the <span class="math">\(F=2\)</span> and <span class="math">\(F=3\)</span> model's performance on the <em>validation</em> set, using ROC curves.</p>
<p>Create a single plot showing two lines:
* one line is the validation-set ROC curve for the <span class="math">\(F=2\)</span> model from 1C (use color BLUE ('b') and style '.-')
* one line is the validation-set ROC curve for the <span class="math">\(F=3\)</span> model from 1D (use color RED ('r') and style '.-')</p>
<p><strong> Short Answer 1c in Report </strong></p>
<p>Compare the two models in terms of their ROC curves from Figure 1. Does one dominate the other in terms of overall performance, or are there areas where one model “wins” and others where the other model does? Which model do recommend for the task at hand?</p>
<p><a id="selecting_thresh"></a></p>
<h4>Selecting the Decision Threshold</h4>
<p>Remember that even after we train an LR model to make probabilistic predictions, if we intend the classifier to ultimately make some yes/no binary decision (e.g. should we give a biopsy or not), we need to select the <em>threshold</em> we use to obtain a binary decision from probabilities.</p>
<p>Of course, we could just use a threshold of 0.5 (which is what <code>sklearn</code> and most implementations will do by default).
Below, we consider several potentially smarter strategies for selecting this threshold.</p>
<p><em>Clarification (10/09)</em>:  To get candidate threshold values, use the helper function <code>compute_perf_metrics_across_thresholds</code> in the starter code file <a href="https://github.com/tufts-ml-courses/comp135-20f-assignments/blob/master/hw2/threshold_selection.py">threshold_selection.py</a>.</p>
<p><strong> Implementation Step 1E </strong> </p>
<p>For the classifier from 1D above (LR for 3-feature dataset), compute performance metrics across all candidate thresholds on the validation set (use <code>compute_perf_metrics_across_thresholds</code>), and pick the threshold that maximizes TPR while satisfying PPV &gt;= 0.98 on the validation set.</p>
<p>Remember, you pick this threshold based on the <em>validation</em> set, then later you'll evaluate it on the <em>test</em> set.</p>
<p><strong> Implementation Step 1F </strong></p>
<p>For the classifier from 1D above (LR for 3-feature dataset), compute performance metrics across all candidate thresholds on the validation set (use <code>compute_perf_metrics_across_thresholds</code>), and pick the threshold that maximizes PPV while satisfying TPR &gt;= 0.98 on the validation set.</p>
<p>Remember, you pick this threshold based on the <em>validation</em> set, then later you'll evaluate it on the <em>test</em> set.</p>
<p><strong> Figure 2 in Report </strong></p>
<p>In one figure with 2 rows and 3 columns, summarize the test-set performance of the F=3 logistic regression model across several thresholds.</p>
<p>Each column should correspond to one of the following models:</p>
<ul>
<li><span class="math">\(F=3\)</span> Logistic Regression (from 1D above), using threshold 0.5</li>
<li><span class="math">\(F=3\)</span> Logistic Regression (from 1D above), using threshold from 1E above</li>
<li><span class="math">\(F=3\)</span> Logistic Regression (from 1D above), using threshold from 1F above</li>
</ul>
<p>Each row should report some performance of the model on the <em>test set</em></p>
<ul>
<li>Top Row: confusion matrix on the <em>test set</em></li>
<li>Bottom Row: TPR and PPV on the <em>test set</em> </li>
</ul>
<p>When you make confusion matrices, use the same orientation as in the day07 slides (true on vertical axis, predicted on horizontal axis, make class 0 before class 1 when you read left-to-right or top-to-bottom).</p>
<p><strong> Short Answer 1d in Report </strong></p>
<p>Compare the 3 confusion matrices in Figure 2. Which model and thresholding strategy best meets our preferences from 1b: avoid life-threatening mistakes at all costs, while also eliminating unnecessary biopsies?</p>
<p><strong> <a name="problem-1e"> Short Answer 1e in Report </strong> </a></p>
<p>By carefully reading the confusion matrices from Figure 2, estimate how many subjects in the test set are saved from unnecessary biopsies that would be done in current practice using your selected thresholding strategy. What fraction of current biopsies might be avoided if this classifier was adopted by the hospital?</p>
<p><em>Clarifications (Added 2020-10-14)</em>:</p>
<ul>
<li>You can assume the current practice is to biopsy every patient. Your goal is to build a classifier that improves on this practice.</li>
<li>You can assume the test set is a reasonable representation of the true population of patients.</li>
</ul>
<h2><a name="problem-2"> Problem 2: Computing the Loss for Logistic Regression without Numerical Issues</h2>
<h4><a name="code-task-2"> Code Task 2: </a> Implement performance metrics for <em>probabilistic</em> classification</h4>
<p>Here, you'll implement some metrics for comparing provided "true" binary labels with <em>real-valued</em> predictions, expressed as either probabilities or as scores.</p>
<p>There's nothing to add to your report here. We just want you to complete these 3 functions below. We'll build on these functions in the next HW.</p>
<p><strong> Task 2(a) </strong> : Implement function <code>calc_mean_binary_cross_entropy_from_probas</code></p>
<p>Starter code file: <a href="https://github.com/tufts-ml-courses/comp135-20f-assignments/blob/master/hw2/performance_metrics_for_proba_predictions.py">performance_metrics_for_proba_predictions.py</a>.</p>
<p>Given a single binary label <span class="math">\(y_n \in {0, 1}\)</span> and a corresponding predicted probability <span class="math">\(p_n \in (0,1)\)</span>, we define binary cross entropy as:</p>
<div class="math">$$
    \text{BCE}(y_n, p_n) = - y_n \log_2 p_n - (1-y_n) \log_2 (1-p_n)
$$</div>
<p>Given the labels for <span class="math">\(N\)</span> examples <span class="math">\(y = \{y_n \}_{n=1}^N\)</span> their predicted probabilities <span class="math">\(p = \{ p_n \}_{n=1}^N\)</span>, we define the <em>mean binary cross entropy</em> for the dataset as:</p>
<div class="math">$$
    \text{mean_BCE}(y, p) = \frac{1}{N} \sum_{n=1}^N \text{BCE}(y_n, p_n)
$$</div>
<p>To keep this computation <em>numerically stable</em>, we will require that your code preprocesses the provided probabilities such that:</p>
<p><span class="math">\(10^{-14} \leq p_n \leq 1 - 10^{-14}\)</span></p>
<p>If we didn't do this, we might call <span class="math">\(\log_2(0)\)</span>, which is not a valid number (NumPy will yield a <code>-np.inf</code> value).</p>
<p>See the starter code for example inputs and the expected output.</p>
<p><a id="logsumexp"> </a> </p>
<p><strong> Task 2(b) </strong> : Implement function <code>my_logsumexp</code></p>
<p>Starter code file: <a href="https://github.com/tufts-ml-courses/comp135-20f-assignments/blob/master/hw2/logsumexp.py">logsumexp.py</a>.</p>
<p>In several ML tasks, given a vector <span class="math">\(a \in \mathbb{R}\)</span> of <span class="math">\(L\)</span> real numbers, we need to frequently evaluate a function like this:</p>
<div class="math">\begin{align}
\text{logsumexp}([a_1, a_2, \ldots a_L])
    &amp;= \log \left( e^{a_1} + e^{a_2} + \ldots e^{a_L} \right)
\end{align}</div>
<p>We call this the "logsumexp" function.</p>
<p>If we just implement this in NumPy code, we'll quickly notice problems for some inputs that should be "easy".</p>
<p>For example, consider the case where our vector <span class="math">\(a\)</span> has two entries: <code>a = [1000, -999]</code>.</p>
<div class="math">\begin{align}
\text{logsumexp}([1000.0, -999])
    &amp;= \log \left( e^{1000} + e^{-999} \right) = 1000 + \epsilon
\end{align}</div>
<p>where we use <span class="math">\(\epsilon\)</span> to indicate a <em>very</em> small positive float value.
The true result is not quite 1000, but probably so close that our finite computers won't be able to represent the difference.</p>
<p>But what does a quick implementation in NumPy do?</p>
<div class="highlight"><pre><span></span><span class="c1"># BAD! Naive computation overflows</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="kp">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="kp">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="kp">exp</span><span class="p">([</span><span class="mf">1000.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">999.</span><span class="p">])))</span>
<span class="ne">RuntimeWarning</span><span class="p">:</span> <span class="n">overflow</span> <span class="n">encountered</span> <span class="ow">in</span> <span class="kp">exp</span>
<span class="kp">inf</span>

<span class="c1"># GOOD: a &quot;numerically stable&quot; computation from a good library</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">logsumexp</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">logsumexp</span><span class="p">([</span><span class="mf">1000.</span><span class="p">,</span> <span class="o">-</span><span class="mf">999.</span><span class="p">])</span>
<span class="mf">1000.0</span>
</pre></div>


<p>How do we implement this in a <em>stable</em> way? 
We can use the "logsumexp trick", which is just a few lines of algebra:</p>
<div class="math">\begin{align}
\text{logsumexp}([a_1, a_2, \ldots a_L])
    &amp;= \log \left( e^{a_1} + e^{a_2} + \ldots e^{a_L} \right)
    \\
    &amp;= \log \left( e^{m} ( e^{a_1 - m} + e^{a_2 - m} + \ldots e^{a_L - m} ) \right)
    \\
    &amp;= \log \left( e^{m} \right) + \log \left( e^{a_1 - m} + e^{a_2 - m} + \ldots e^{a_L - m} \right)
    \\
    &amp;= m + \log \left( e^{a_1 - m} + e^{a_2 - m} + \ldots e^{a_L - m} \right)
\end{align}</div>
<p>
The above is true for <em>any</em> scalar real value <span class="math">\(m\)</span>. However, if we pick <span class="math">\(m\)</span> smartly, this computation becomes more robust to any possible input values in our vector <span class="math">\(a\)</span>.</p>
<p>If we select <span class="math">\(m\)</span> equal to the maximum entry of the vector <span class="math">\(a\)</span> (<span class="math">\(m = \max_{\ell} a_{\ell}\)</span>), we can guarantee that each of these right-hand side terms indexed by <span class="math">\(\ell\)</span> satisfy: <span class="math">\(0 \leq e^{a_\ell - m} \leq 1\)</span>.
Furthermore, at least one of these terms equals 1.0 precisely. Thus, the total sum inside the log must be between 1 and <span class="math">\(L\)</span>. We can easily compute <code>np.log(1.0)</code> or <code>np.log(L)</code> and values in between for any reasonable value of <span class="math">\(L\)</span> (even if our vector has a few billion entries).</p>
<p>By implementing the last line above in our computer and setting <span class="math">\(m\)</span> to the maximum entry of our vector <span class="math">\(a\)</span>, our computation will be correct no matter <em>what</em> the entries of <span class="math">\(a\)</span> are, so long as they are representable as a valid `float64' value in your computer. The input <span class="math">\(a\)</span> could contain extreme negative values like -9999.999, or extreme positive values like 987654.123. </p>
<p><a id="2c"></a>
<strong> Task 2(c) </strong> : Implement function <code>calc_mean_binary_cross_entropy_from_scores</code></p>
<p>Starter code file: <a href="https://github.com/tufts-ml-courses/comp135-20f-assignments/blob/master/hw2/performance_metrics_for_proba_predictions.py">performance_metrics_for_proba_predictions.py</a>.</p>
<p>Given a single binary label <span class="math">\(y_n \in {0, 1}\)</span> and a corresponding real-valued score <span class="math">\(s_n \in (-\infty, \infty)\)</span>, we define binary cross entropy as:</p>
<div class="math">\begin{align}
    \text{scoreBCE}(y_n, s_n) = \text{BCE}(y_n, \sigma(s_n)) &amp;= - y_n \log_2 \frac{1}{1 + e^{-s_n}} - (1-y_n) \log_2  \frac{e^{-s_n}}{1 + e^{-s_n}}
    \\
    &amp;= \begin{cases}
    \log_2 (1 + e^{-s_n}) \quad \text{if}~ y_n = 1
    \\
    \log_2 (1 + e^{s_n}) \quad \text{if}~ y_n = 0
    \end{cases}
    \\
    &amp;= \log_2 \left( 1 + e^{\text{flip}(y_n) s_n} \right)
    \\
    &amp;= \log_2 \left( e^0 + e^{\text{flip}(y_n) s_n} \right)
    \\
    &amp;= \frac{\text{logsumexp}( [0, \text{flip}(y_n) s_n ] )}{ \log_e(2) }
\end{align}</div>
<p>Here, we assume the <code>logsumexp</code> function (which uses the "natural" or base-<span class="math">\(e\)</span> logarithm) is defined above in <strong>2(b)</strong>.
The function <code>flip</code> is defined as:</p>
<div class="math">\begin{align}
\text{flip}(y_n)
 &amp;= \begin{cases}
    -1 \quad \text{if}~ y_n = 1
    \\
    +1 \quad \text{if}~ y_n = 0
    \end{cases}
\end{align}</div>
<p>You are expected to return a <em>base 2</em> logarithm value here, so the final <span class="math">\( \log_e 2\)</span> term accounts for this.</p>
<p>Remember that if it is easy to compute a logarithm in base "B", but you want a logarithm in base "A", you can convert between bases like so for any input value <span class="math">\(z\)</span>:</p>
<div class="math">$$
\log_A(z) = \frac{\log_B(z)}{\log_B(A)}
$$</div>
<p>Reference <a href="https://www.khanacademy.org/math/algebra2/x2ec2f6f830c9fb89:logs/x2ec2f6f830c9fb89:change-of-base/a/logarithm-change-of-base-rule-intro">https://www.khanacademy.org/math/algebra2/x2ec2f6f830c9fb89:logs/x2ec2f6f830c9fb89:change-of-base/a/logarithm-change-of-base-rule-intro</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
  </div>
</article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
      <div class="row">
       <ul class="col-sm-6 list-inline">



        </ul>
        <p class="col-sm-6 text-sm-right text-muted">
          MIT License
          /
          <a href="https://github.com/tufts-ml/tufts_ml_website">
          Source on github
          </a>
          /
          <a href="https://github.com/getpelican/pelican" target="_blank">Powered by Pelican</a>
          /
          <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
        </p>
      </div>
    </div>
  </footer>
</body>

</html>